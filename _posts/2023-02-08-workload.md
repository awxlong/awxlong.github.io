---
layout: post
title: "Presentation on Neuro-Symbolic AI: An Emerging Class of AI Workloads and their Characterization" #a post with audios
date: 2023-02-08 10:42:00
description: my presentation on the paper by Susskind et al. (2021)
tags: food-for-thought
toc:
    sidebar: left
categories: blog-post
disqus_comments: true
---

_Neuro-Symbolic AI: An Emerging Class of AI Workloads and their Characterization_ is a paper by [Susskind et al. (2021)](https://arxiv.org/abs/2109.06133v1) I discussed in Dr. Antonio Vergari's weekly lab meeting. 

These were my [slides](https://awxlong.github.io/assets/pdf/feb_8th_presentation.pdf).

These were my notes:

- What are neuro-symbolic models?

    - I used to think they would replace neural networks; in reality they either extend the expressiveness of either symbolic models or neural models
    - This paper discusses how NeSy models are actually assembly of models; a dominant neural model that does low-level perception can answer more symbolic questions 
    - How can you apply parallel computing techniques given the symbolic component of NeSy hybrid architectures?


| Model      | Submodules                                                                                   | Task                                | Dataset                      |
|----------------|----------------------------------------------------------------------------------------------|-------------------------------------|------------------------------|
| NSCL by IBM/MIT| - Image Parser (Object detection/masking)                                                    | Query-driven Relational reasoning over images | CLEVR                        |
|                | - Question Parser (Natural Language Processing)                                              |                                     |                              |
| NS-DR by IBM/MIT| - Video Frame Parser (Object detection/masking)                                               | Query-driven relational reasoning over video | CLEVRER                      |
|                | - Question Parser (Natural Language Processing)                                               |                                     |                              |
|                | - Dynamics Predictor (Learned physics)                                                        |                                     |                              |
| NLM by Google  | - No Submodels                                                                               | Program-driven reasoning            | Sort, Family tree, and Blockâ€™s world |


- Operational intensity refers to the ratio of computation performed by an algorithm or application to the data transferred between memory and processing elements. It represents how many operations are performed on a unit of data. Algorithms or applications with high operational intensity require a lot of computation per unit of data, which can result in a high power consumption.
- Data intensity, on the other hand, refers to the ratio of data transferred by an algorithm or application to the computation performed. It represents how much data is transferred for a unit of computation. Algorithms or applications with high data intensity require a lot of data transfer for a unit of computation, which can result in slow performance and high memory usage.
