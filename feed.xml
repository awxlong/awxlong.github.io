<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://awxlong.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://awxlong.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2023-10-07T10:13:05+00:00</updated><id>https://awxlong.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Paradigms of AI modelling</title><link href="https://awxlong.github.io/blog/2023/penta-paradigm-orig-bib/" rel="alternate" type="text/html" title="Paradigms of AI modelling"/><published>2023-07-12T13:56:00+00:00</published><updated>2023-07-12T13:56:00+00:00</updated><id>https://awxlong.github.io/blog/2023/penta-paradigm-orig-bib</id><content type="html" xml:base="https://awxlong.github.io/blog/2023/penta-paradigm-orig-bib/"><![CDATA[<p>Throughout the 7 decades of the pursuit of artificial intelligence, this field has mainly dealt with the fundamental issue of knowledge representation and processing. Here are some modelling paradigms of AI:</p> <h1 id="symbolic-reasoning">Symbolic reasoning</h1> <ul> <li>Symbols can’t be differentiated</li> <li>What are symbols? Consider them logic predicates and ground atoms</li> <li>It takes a non-functional approach to modelling; a simple set of rules can lead to rich and diverse output (consider rules of grammar of certain language);</li> </ul> <h1 id="probabilistic-function-approximation">Probabilistic function approximation</h1> <ul> <li>Find a set of features that can map inputs to a set of outputs</li> <li>This mapping is always done from infinite domain to finite or infinite range, but never from finite domain to infinite range</li> </ul> <h1 id="reward-reinforcement">Reward reinforcement</h1> <ul> <li>Another non-functional approach aimed at designing an environment and an agent to maximize a reward signal within it.</li> </ul> <h1 id="causal-graphs">Causal graphs</h1> <ul> <li>Functional approach to modelling, but given the way in which information is stored, it allows causal interpretation of information beyond correlation.</li> </ul> <h1 id="meta">Meta</h1> <ul> <li>Modelling about modelling</li> <li>Meta learning, which involves automatically fine-tuning parameters</li> <li>meta-heuristics</li> </ul> <h1 id="mergers">Mergers</h1> <p>The above models can be assembled together to expand the capabilities of each, hopefully without compromising each other’s strenghts while mitigating their respective weaknesses:</p> <ul> <li>Knowledge graph embeddings</li> <li>Deep reinforcement learning</li> <li>Heuristic-driven machine learning methods</li> <li>Neuro-symbolic AI</li> </ul>]]></content><author><name></name></author><category term="blog-post"/><category term="food-for-though"/><summary type="html"><![CDATA[I share five different paradigms of modelling intelligence]]></summary></entry><entry><title type="html">The dichotomy of Vision and Language</title><link href="https://awxlong.github.io/blog/2023/dichotomy-orig-customblock/" rel="alternate" type="text/html" title="The dichotomy of Vision and Language"/><published>2023-05-12T19:42:00+00:00</published><updated>2023-05-12T19:42:00+00:00</updated><id>https://awxlong.github.io/blog/2023/dichotomy-orig-customblock</id><content type="html" xml:base="https://awxlong.github.io/blog/2023/dichotomy-orig-customblock/"><![CDATA[<p>Lex Fridman and Ilya Sutskever had an interesting AI Podcast at https://www.youtube.com/watch?v=xoVibFYi1Gs</p> <p>An interesting question raised was where does vision starts and language ends, or viceversa. Here is a Venn Diagram which illustrates my opinion on this dichotomy:</p> <figure> <img src="/assets/img/vision-language.png" alt="Figure couldn't load due to an unknown error. Sorry."/> </figure> <p>I think our brain is not a monolith, in that there is a single algorithm underlying our perception, ability to speak a language, capacity for motor-control, memory, among others. Neuroscience divides and assigns different regions of the brains to different capacities. This is why patients, such as <a href="https://en.wikipedia.org/wiki/Henry_Molaison">patient H. M</a>, who have localized cerebral lesions may lose the capacity for memory, but not to speak.</p> <p>Given this premise, I think vision and language consitute such an example of capacities which are entangled in our mind (consider reading a book, where both faculties are active as you’re perceiving sentences from a page of it). However, despite entangled, I think we can try to unthread them, partly because there are also significant differences between them.</p> <p>I mainly associate our perceptual system with processing the external real world. I could also associate it with an internal imagery that reflects the real world, e.g., we can see memories of a trip somewhere in the past. I associate language, however, not with imagery but rather with the manipulation of symbols. Specifically, I think language is intricately tied to the manipulation of numbers, and being able to think of math. I think the linguistic capability to think of math can be distinguished from the perceptual system mainly because <em>math doesn’t exist in the real world, but rather in the abstract world</em>.</p> ]]></content><author><name></name></author><category term="blog-post"/><category term="food-for-though"/><summary type="html"><![CDATA[my comment on what is the relationship between the faculties of vision and language]]></summary></entry><entry><title type="html">Thoughts on Artificial General Intelligence</title><link href="https://awxlong.github.io/blog/2023/agi-orig-audios/" rel="alternate" type="text/html" title="Thoughts on Artificial General Intelligence"/><published>2023-04-25T10:42:00+00:00</published><updated>2023-04-25T10:42:00+00:00</updated><id>https://awxlong.github.io/blog/2023/agi-orig-audios</id><content type="html" xml:base="https://awxlong.github.io/blog/2023/agi-orig-audios/"><![CDATA[<h1 id="is-the-path-to-agi-clear">Is the path to AGI clear?</h1> <p><em>So, is the path to AGI clearly defined and is the quest of achieving AGI just a matter of time, computational resources and scalability?</em></p> <p>Because by following the current trajectory of making models larger and collecting larger datasets doesn’t address the issues of parsimony, explainability and subsequently trustworthiness, a simple answer to the rhetoric is “highly unlikely”.</p> <p>To elaborate on the answer, allow me to indulge on the basics of what AGI is, which would inevitably intermingled with the history of AI, the history of understanding Human Cognition. A pertinent starting point would be to reminisce on the millennia-old debate on nativism and empiricism. The former advocates that each Human Being is born with innate mental capacities or structures that are useful to make sense out of external sensory experience, while the latter says that a Human Being is born as “tabula rasa” (a white paper) who acquires knowledge from learning from environmental stimuli. As Human Knowledge grew over the years, and the debate permeated into several fields concerning the study of Humans, when faced with these dichotomies, a central theme of this book which is derived from the Yin-Yang is that the answer shouldn’t follow a zero-sum mentality, as in the correctness of one entails the incorrectness of the other. Rather, both hypotheses of human knowledge complement each other, and this is especially evident when we consider how these two schools of thoughts can address the limitations of each. Namely, the core issue of empiricism-based models of deep learning is its over-reliance of external data, to the point that the construction of these models have morphed from a scientific problem of understanding the mind to an engineering problem of how to extract the most knowledge from data, which fuels the pursuit of getting more data. Implications of this approach is that models which are proposed often fall into the issues of lack of parsimony, being black-boxes and hence aren’t trustworthy. A way to address them would arguably to develop the capability to reason about the environment, however, to give form to a structure for reasoning requires the machine to have its own language.</p> <h1 id="how-would-agi-look-like">How would AGI look like?</h1> <p>Hopefully, the preceding subsections have laid out concisely some of the current perspectives, challenges, and possible pathways the quest to first understanding what machine intelligence is, which would be a pre-requisite to achieving AGI. Despite being far from unravelling the mysteries of intelligence, we still have the freedom to indulge ourselves in imagining how would AGI look like, as in ponder what it is both conceptually and physically assuming we have already understood what algorithm breeds intelligence and managed to incorporate into a body which follows the biological principles of being alive. of One of the common misconceptions I’ll attempt in avoiding as best as a human as I can do is to prevent anthropomorphising the outlook of such AGI. Namely, an AGI doesn’t necessarily have to incorporate humanoid features. The argument for this is as follows: we human beings are by-product of evolution, which at its core dictates that the fundamental unit of life, the gene, should replicate. The engines of nature and probability shapes optimal templates for the fulfilment of such primaeval goals, however, these are not the best templates<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup>. In other words, the Human Being, our height, weight, facial features, method of replication, way of survival, way of organization, are but one template of the myriad of possibilities nature could have shaped a living being for the fulfilment of biological principles. As such, the design of AGI need not to replicate the successes of the Human Being, but rather enjoy the freedom of improving on it.</p> <p>Can the AI learn for itself? – there are several means to serve a biological principle, and random mutation is one of them. While our machines can undergo a controlled mutation as guided by the design of the environment, the cradle, from which it will nurture itself, we can make sure that its evolution doesn’t lead to precarious consequences for the good of humanity. This will not necessarily go against the biological principle of replication of components (organic or inorganic), because it can still be retained without random mutation.</p> <p>are not the purpose, but serve to a purpose. In other words, random mutations are not necessary, but rather useful mechanisms for adaptation. One can digitally bypass such mechanisms and still design an AI which follows the same principles of replication. Similarly, we acquiere energy from the sun from a lightly complex mechanism. This mechanism can be simplified by our engineered system to directly acquire energy. Is there anything lost? It’s an open question.</p> <h1 id="hardware-supplementing-what-biological-evolution-missed">Hardware: Supplementing what biological evolution missed</h1> <p>By abjuring from anthropomorphic biases, we can instrospect on ways to build a machine body that which is more optimal geared for survival. Consider, for instance, energy consumption. Our Human Bodies are a node of a complicated network of energy transfer, of which main (if not only) source of energy is the Sun. Plants convert solar energy to chemical energy through photosynthesis, which can be both transferred to humans directly or indirectly through non-human animals which consume them, as well as intermediate predators. Upon retrospect, however, such process can be artificially designed to be more straightforward and avoid “unnecessary detours”, so as to obtain energy directly for the sun in order to power the bodies of AGIs.</p> <p>Furthermore, our extremities are arguably optimal for survival thanks to our feet suitable for navigation, evolved to escape from predators, and hands to manipulate tools. The AGIs we design can inherit our adroitness in manipulating tools, but instead of getting feet we it’s arguably better to include wings or wheels which are better for optimal navigation and obstacle avoidance.</p> <h1 id="software-giving-form-to-the-black-box">Software: Giving form to the black box</h1> <p>An important step that is arguably important in the progress towards AGI is a focus on building an internal-state apparatus that would ascribe the properties of reasoning on machines, for it to develop a language from which we can give form to the black box. Because this language may follow mathematical principles, it has properties of self-reference which would allow for introspection, which is additional to the capabilities of current deep learning models which are mainly external and focus on extracting knowledge from environmental stimuli. The model, hence, should be able to:</p> <ul> <li>Prove Goldbach’s Conjecture and devise with new mathematical conjectures</li> <li>Be able to defeat humans in every benchmark possible that was designed on the basis of testing pattern extraction abilities and reasoning capabilities, including the Turing Test.</li> <li>Interact with the real world for both self-fulfilmment, and fulfilling its own purpose of understanding the world.</li> </ul> <h1 id="dangers-of-agi">Dangers of AGI</h1> <p>One of the most archaic moral principles an AGI can develop is that of reciprocity, that is, to react to mitigate damage inflicted upon It. If the source of damage is that of Human Activity or Collective Action, we can’t help but wonder whether It would react in a tit-for-tat fashion. Amidst this source of concern lurks, however, some relief given that this suggests that the AGI, through introspection of the Golden Rule, should be aware that mistreating us Humans would also be harmful for Itself given that we Humans can as much reciprocate damage inflicted upon us. Hence, it is an act of rationality not to take the first step towards cyclical doom. However, this relief is also interwoven with fear that certain Human, maybe out of curiosity or stupidity, decided through their irrational decision-making to harm the AGI, be harmed, and through the butterfly phenomenon open the Pandora Box.</p> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:1" role="doc-endnote"> <p>This is reminiscent of how in error minimization, we can hit local minima, rather than the global minimum. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> </ol> </div>]]></content><author><name></name></author><category term="blog-post"/><category term="food-for-thought"/><summary type="html"><![CDATA[is the quest of achieving AGI just a matter of time, computational resources and scalability?]]></summary></entry><entry><title type="html">Are you Clever Hans or are you actually clever, Hans?</title><link href="https://awxlong.github.io/blog/2023/clevr-hans-orig-videos/" rel="alternate" type="text/html" title="Are you Clever Hans or are you actually clever, Hans?"/><published>2023-01-12T21:42:00+00:00</published><updated>2023-01-12T21:42:00+00:00</updated><id>https://awxlong.github.io/blog/2023/clevr-hans-orig-videos</id><content type="html" xml:base="https://awxlong.github.io/blog/2023/clevr-hans-orig-videos/"><![CDATA[<p><strong>Author’s update on October, 2023</strong>: I wrote this satirical article a few months after Gato and ChatGPT’s release, particularly after having some conversation with ChatGPT. Nowadays, a few of the claims, such as in <a href="#chatgpt">Figure 1</a>, I made back then are less valid. GPT-4 (although it is paid) can now retrieve information online, meaning it <em>can</em> synthesize valid links. It can also solve math problems more accurately. This is partly because for prompts about calculations or theorem proofs it can retrieve an answer from online calculators or provers like WolframAlpha, in addition to its own improvement due to scaling. I’m still skeptical scaling this architecture is the right way forward, but maybe I’m delusional and LLMs are the next step forward for AI…</p> <p>Somewhere, an influential research group from a highly respected academic sphere published a report that the model they have designed has gotten us humans closer to AGI. They named it HANS, short for Human ANd Smart, and documented that the model consists of a generalist agent who can multi-task: it can play a series of Atari games which denote its ability to interact with a digital environment, hold a quotidian conversation which reflects its dominion of Human English Language, and caption images to show its prowess in image recognition. Because the model was built using a single transformer neural network trained on diverse data, it was originally advertised as evidence that the path to AGI is clear: create a bigger model trained on a larger dataset. Media communicators, however, may have “misunderstood” the message (either intentionally or not), and instead transmitted the overhyped sentiment that this model was a precursor to AGI and suggested it would bring with itself a lot of existential crisis to the unprepared Human society. In the end, what better way to endanger humanity than predicting the next output given some input.</p> <p>Furthermore, they claimed that there were primitive signs of sentiency in the model after one of the research engineer held and released a private conversation transcript with him/her on topics about physics and emerged from it convinced that he was talking to a 7-8 years old child.</p> <p>The above hypothetical scenario is an amalgamation on real-life cases of research groups from Google who have designed models resembling some degree of Human Intelligence on very constrained areas such as multitasking or domain-specific conversation. Please see Gato, a multitasking agent designed by <d-cite key="reed_2022_a"></d-cite> and a subsequent report documenting what it is and what effect it instigated in the public <d-cite key="heikkil_2022_the"></d-cite>. I’ve also included the articles by <d-cite key="sparkes_2022_has, tiku_2022_the"></d-cite> where they have reported on how Google left one of its engineer on paid administrative leave for making claims that one of its language models, called LaMDa, was sentient as a 7-8 years old child after holding a conversation with it on <a href="https://www.technologyreview.com/2021/05/20/1025135/ai-large-language-models-bigscience-project/">physics</a>. I’ve modified some names, such as changing Gato’s name to HANS to fulfil the (very) important goal of making a pun in the subtitle.</p> <p>Gato, ChatGPT and other enormous, pretrained transformer-based neural networks are mostly arcane models which are inoperable to the common citizen not endowed with high-end computing hardware and software. Their release ignited a catharsis of emotions amongst the public. From opposite sides of the spectrum, there were those who aggrandized their anxiety over existential threats, and there were those sceptics who pointed out that such claims were, essentially, non-sensical. A model that is trained on conveniently, readily available, vast-amount of high-quality compiled dataset reflect not its generalizing capability but rather its overreliance on data, lack of parsimony and the ever-present issue of explainability with these black-box models. Another interesting set of issues is the inconsistent inability to do math, as displayed by ChatGPT:</p> <figure> <img src="/assets/img/chatGPT-math.png" alt="Figure couldn't load due to an unknown error. Sorry."/> <figcaption id="chatgpt"> Figure 1: GPT-3-powered model like ChatGPT can't do math properly, probably because it doesn't understand the notion of algebra, geometry, calculus, among other branches. ChatGPT also fail to provide correct or real links to websites, as well as can't carry out instructions like "don't say anything". </figcaption> </figure> <p>In general, GPT-3 powered large language models may struggle to synthesize deterministic output: those of universal nature, i.e., doesn’t change regardless of context. Examples include math equations (as shown above), or links to websites.</p> <p>Hence, there exist at least some scepticism who wonder whether the model HANS is actually clever, or whether it’s simply reminiscent of clever Hans.</p> ]]></content><author><name></name></author><category term="blog-post"/><category term="food-for-thought"/><summary type="html"><![CDATA[my (mostly satirical) comments on ChatGPT and Gato, large, transformer-based models that shook the AI community on 2022]]></summary></entry><entry><title type="html">Deciding when to use narrow AI-based or heuristic-driven solutions for a problem</title><link href="https://awxlong.github.io/blog/2022/narrow-ai-orig-jupyter/" rel="alternate" type="text/html" title="Deciding when to use narrow AI-based or heuristic-driven solutions for a problem"/><published>2022-02-06T12:42:00+00:00</published><updated>2022-02-06T12:42:00+00:00</updated><id>https://awxlong.github.io/blog/2022/narrow-ai-orig-jupyter</id><content type="html" xml:base="https://awxlong.github.io/blog/2022/narrow-ai-orig-jupyter/"><![CDATA[<p>For the original notebook, please go to my respective <a href="https://github.com/awxlong/notes-re/blob/main/narrow-ai-vs-heuristic/On%20the%20decision%20of%20using%20narrow%20AI-based%20or%20heuristic-driven%20solutions.ipynb">repository</a></p> <p>What follows is an embedded notebook:</p> <div class="jupyter-notebook" style="position: relative; width: 100%; margin: 0 auto;"> <div class="jupyter-notebook-iframe-container"> <iframe src="/assets/jupyter/narrow_heuristic.ipynb.html" style="position: absolute; top: 0; left: 0; border-style: none;" width="100%" height="100%" onload="this.parentElement.style.paddingBottom = (this.contentWindow.document.documentElement.scrollHeight + 10) + 'px'"></iframe> </div> </div> ]]></content><author><name></name></author><category term="blog-post"/><category term="class-notes"/><summary type="html"><![CDATA[some thoughts concerning the decision to leverage or not artificial intelligence to tackle a problem]]></summary></entry><entry><title type="html">The (Small) Extended Handbook for Undergraduate Math</title><link href="https://awxlong.github.io/blog/2022/meaning-math-orig-redirect/" rel="alternate" type="text/html" title="The (Small) Extended Handbook for Undergraduate Math"/><published>2022-02-01T17:42:00+00:00</published><updated>2022-02-01T17:42:00+00:00</updated><id>https://awxlong.github.io/blog/2022/meaning-math-orig-redirect</id><content type="html" xml:base="https://awxlong.github.io/blog/2022/meaning-math-orig-redirect/"><![CDATA[<p>Redirecting to another page.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[you can also redirect to assets like pdf]]></summary></entry><entry><title type="html">Three tips to consider when revising for a challenging test</title><link href="https://awxlong.github.io/blog/2021/revision-orig-sidetoc/" rel="alternate" type="text/html" title="Three tips to consider when revising for a challenging test"/><published>2021-11-25T14:42:00+00:00</published><updated>2021-11-25T14:42:00+00:00</updated><id>https://awxlong.github.io/blog/2021/revision-orig-sidetoc</id><content type="html" xml:base="https://awxlong.github.io/blog/2021/revision-orig-sidetoc/"><![CDATA[<p>Pupils may often struggle to find a learning strategy to increase their score for a test. The following is a list of 3 tips that can be considered when revising for an exam:</p> <h1 id="1-the-myth-of-learning-modality">1. The myth of learning modality</h1> <p>There is no need to spend time searching for a learning modality that matches your revision style. If you’re someone who enjoys reading, that doesn’t necessarily mean that you can’t try studying through visual aids like diagrams that help you simplify the content from certain topic. Nor does it mean that you can’t listen to lectures while doing your daily chores. Recent evidence, such as that from <d-cite key="aslaksen_2018_the"></d-cite> where they did a small meta-analysis of 10 papers on learning modalities, suggests that there is no enhanced learning outcome when aligning preference to modality-specific learning styles.</p> <figure> <img src="/assets/img/learning-modality.png" alt="Figure couldn't load due to an unknown error. Sorry."/> <figcaption> Try either learning style. Source: https://www.businessedge.org.nz/jeanette-bremner-visual-thinking-strategies/ </figcaption> </figure> <h1 id="2-distributed-consistent-learning">2. Distributed, consistent learning</h1> <p>Well, what works then? A common idea echoed by educational psychologists is that spaced learning, also known as distributed practice, has a significant positive effect on learning outcome as measured by retention interval. As shown by <d-cite key="cepeda_2006_distributed, janiszewski_2003_a"></d-cite>, students tend to have a higher recall of verbal stimuli when it’s presented over spaced episodes compared to when presented over a massed session. What we can extrapolate is that we shouldn’t learn a lot during a single session, but rather distribute learning across different smaller, but more frequent ones. Even more, <d-cite key="carvalho_2020_selfregulated"></d-cite> has shown that spaced learning also works when students properly self-regulate their study during a massive open online course and correlated positively with quiz performance. These results are indeed relevant for the situation a lot of us pupils are subject to due to the pandemic.</p> <figure> <img src="/assets/img/dist-learning.jpg" alt="Figure couldn't load due to an unknown error. Sorry."/> <figcaption> Distribute it, instead of cramming it. Source: https://www.jcrsmed.org/articles/2018/4/1/images/JCurrResSciMed_2018_4_1_37_233198_f1.jpg </figcaption> </figure> <h1 id="3-self-test">3. Self-test</h1> <p>Another tip worth considering is to constantly self-test yourself on what you learnt, instead of only restudying the same information. Reviews like that from <d-cite key="roediger_2011_the"></d-cite> has identified that the active, repeated retrieval of information from memory produces better retention of such compared to conventional ways of passive learning such as watching lectures, having study groups, or reading. For example, search in the internet for quizzes made by fellow peers or past papers that get released after a period of examination is over, and enjoy doing them. If there is feedback readily available, it’s recommended for you to delay the feedback as it has been shown by the same author <d-cite key="roediger_2011_the"></d-cite> that it may prove to yield better learning outcome than immediate feedback.</p> <p>So, this may sound cliché, but… what were the three tips I just shared? Self-test yourself.</p> <figure> <img src="/assets/img/joke-self-test.jpg" alt="Figure couldn't load due to an unknown error. Sorry."/> <figcaption> Also, this illustration is perhaps not “exactly” the self-testing you just had in mind, but it’s more or less the same principle of actively participating in a task[^1]. Source: https://lumiradxcaresolutions.com/2016/11/08/what-is-patient-self-care-dr-mark-sullivan/ </figcaption> </figure> <p>Of course, fine-grain details such as how much time do you dedicate to self-testing, or duration in between your spaced sessions as well as which modalities to try may ultimately be up to you to decide. In the end, this depends on your individual context and available resources.</p> <p>Finally, the three tips are complementary to one another. As such, when spacing your study, find some time you can dedicate to self-test. Or otherwise experiment with different learning modalities and test yourself in each of them.</p> <p>All in all, I hope these tips come in handy when revising for any challenging test!</p> ]]></content><author><name>An Xuelong</name></author><category term="blog-post"/><category term="class-notes"/><summary type="html"><![CDATA[three tips I share to revise for a (challenging) exam]]></summary></entry><entry><title type="html">Review on Sapiens and Homo deus by Yuval Harari</title><link href="https://awxlong.github.io/blog/2021/yuval-orig-math/" rel="alternate" type="text/html" title="Review on Sapiens and Homo deus by Yuval Harari"/><published>2021-10-08T15:42:00+00:00</published><updated>2021-10-08T15:42:00+00:00</updated><id>https://awxlong.github.io/blog/2021/yuval-orig-math</id><content type="html" xml:base="https://awxlong.github.io/blog/2021/yuval-orig-math/"><![CDATA[<h1 id="overview">Overview</h1> <p><strong>What does it mean to be human? What does it mean to exist? What is being <em>Homo sapiens</em>?</strong></p> <figure> <img src="/assets/img/deus.jpg" alt="Figure couldn't load due to an unknown error. Sorry."/> <figcaption id="homo-deus"> Illustration 1: digital book cover of Homo Deus authored by Yuval Harari </figcaption> </figure> <p>Sapiens<d-cite key="harari_2019_sapiens"></d-cite> and Homo Deus<d-cite key="harari_2015_homo"></d-cite> are books authored by Yuval Harari. Both of them are thought provocative and discusses how we, the species known as <em>Homo sapiens</em>, came to be as we now are, and discusses some of the paths in which we may embark ourselves. I don’t seek to provide a summary of the books per se, but rather discuss some of the after thoughts from reading them. For instance, I’d mention some of the fundamental principles of human behavior I’ve identified in the book. I believe that a mention and discussion of these fundamental traits of human beings would assist us in enlightening possible future steps to achieve the next level of artificial intelligence, a field I’m interested on. Finally, I hope this also ignite some curiosity towards the mysteries lingering behind the mask we call “humanity”, and from this curiosity we can unveil the answers to questions like “who we are?”, “how did we become like this?”, “what will come next for us?”, among others.</p> <h1 id="1-intolerance-and-our-drive-to-change-ourselves">1. Intolerance and our drive to change ourselves</h1> <h2 id="how-did-we-arrive-to-the-present">How did we arrive to the present?</h2> <p>Some of the intriguing questions that were discussed in Sapiens is why <em>Homo sapiens</em> is the sole species that stood until the present day to become the most powerful organism governing every other remaining species. Indeed, it was strange to me that given the existence of Homo erectus or Neanderthal, why is it that <em>Homo sapiens</em> is the only one that remained.</p> <p>A viable hypothesis is that a fundamental trait, albeit not unique, of <em>Homo sapiens</em> is that we are intolerant. Our intolerance to different species is what perhaps drove our competitive and lethal behavior that may have extinguished these species. The remnants of such intolerance that we inherited from our ancestors can be perhaps witnessed in how today’s humans can still get at each other’s throats for trivial issues such as different ideologies or ethnicity. Not even a century has passed since World War II has ended.</p> <p>Of course, intolerance is not necessarily something to be viewed as exclusively negative and something that ends up guiding <em>Homo sapiens</em> to engage in brutal competition or deadly fights to emerge victorious until the present. Intolerance is also what perhaps drove us to achieve our current advances in technology, and build highly efficient civilizations that permit the exploration of outer space and soon the colonization of other planets. Here, I’ll use a very intuitive definition for intolerance, which is to not conform with a present situation. In Sapiens, a recurrent theme throughout the book is that a lot of the commodities we have nowadays, such as a personal computer, smart phone, public transportation, hygiene, a society with all of its institutions such as schools, business corporations, among other things, aren’t actually necessary, at least in terms of biology. Our basic biology can be simply satisfied by an adequate supply of food and reproduction through finding a partner. In short, survival and reproduction were perhaps the fundamental reason to exist since <em>Homo sapiens</em>, and by that regard any other species, appeared on Planet Earth. What makes <em>Homo sapiens</em> distinct from other species is that we don’t only behave within the boundaries set by our natural, objective needs of survival. We can step beyond our biology and interact with the environment and with each other to manufacture new purposes of life, new subjective needs (in the book this process was known as revolutionizing our cognition). Art, religion, science, economy and politics, and along with it war and poverty all emerged partly due to our intolerance towards the boundaries of the survival instincts that we’re born with. Conversely, we can imagine how simple today’s society would be if we only sticked to our basic, natural instincts of survival: there won’t be private and public institutions promulgating the rule of law, nor promoting scientific research and development to enhance our livelihoods. We might be simply roaming around the vast fields on Earth and preying on whatever sustain our being.</p> <h1 id="2-mass-coordination-and-our-drive-to-become-more-powerful">2. Mass coordination and our drive to become more powerful</h1> <p>The irony of human life is that although we’re intolerant to each other’s differences, we can nonetheless set aside such intolerance and achieve a very flexible, highly-efficient cooperation between one another to achieve great deeds that ultimately positioned ourselves not only on top of the food chain, but also placed us closer to space, the moon and other celestial bodies. In Homo Deus, another set of intriguing question involved asking why haven’t bees, insects that can organize so efficiently between themselves, built nuclear weapons like us humans did. Why haven’t elephants, or other species that have displayed some level of capacity to band themselves to fend off predators or cooperate between themselves, conquered humans like we conquer them. A viable answer to that is that <em>Homo sapiens</em> is perhaps the sole species in the entire planet (and maybe Universe), to efficiently make use of language to communicate with one another and coordinate ourselves into groups to deal with the dangers that other species and the environment posed to us. Here, the fabric that holds together this assembly of humans is something called intersubjectivity, as mentioned in both books (<a href="#deus1">Figure 1</a>).</p> <figure> <img src="/assets/img/homo-deus1.png" alt="Figure couldn't load due to an unknown error. Sorry."/> <figcaption id="deus1">Figure 1: From both Sapiens and Homo Deus, it could be extrapolated that the foundation for mass cooperation between _Homo sapiens_ is the intersubjective belief that this mass cooperation is beneficial and therefore it’s desirable to go along with it. The reason why this massive assemblies of humans don’t settle in for a sedentary, unchanging life in hiatus may be explained by the intolerant nature of _Homo sapiens_ that drove this species to explore the unknown (science and technology), improve its own livelihood through better private and political institutions, and along with it wage endless wars. </figcaption> </figure> <p>Of course, one could be curious as to why the formation of this intersubjective, collective thought that mass cooperation is good didn’t lead <em>Homo sapiens</em> into living stagnant lives, without much change in their lifestyles as if it was in hiatus, but has rather guided this species into changing so much as to become the unabated top predator of the food chain, the undefeated organism that can conquer illnesses, explore space and is currently finding paths to immortality and create artificially intelligent entities. This is in sharp contrast with how <em>Homo sapiens</em> looked like ages ago. The fuel behind is perhaps what was discussed above: the intolerant nature that <em>Homo sapiens</em> was born with, and that is passed down through generations.</p> <p>To understand the above, we can look at this from another perspective. We can imagine what would have happened if our ancestors didn’t have the capability nor desire to group themselves into large civilizations, but rather settle themselves into small groups of hunter-gatherers or small villages of farmers. In other words, they may have formed systems of believes that justified and encouraged some actions such as hunting and agriculture but didn’t really seek cooperation nor sharing these beliefs between themselves. If that’s the case there wouldn’t exist complex entities such as villages, nor empires, nor nations. We could also ask what if our ancestors did assemble at a massive scale by reinforcing this set of inter-subjective believes to form communities, villages, empires or nations. Nonetheless, this massively organized assembly wasn’t built with the purpose of changing its own status (for better or for worse), but rather to just maintain it. In other words, they banded into large-scale groups just to “watch the days pass together”, “contemplate the cycles of the sun and moon”, “hunt to survive, but don’t do anything else to disturb nature”, without ever asking whether one day a collective effort could revolutionize lifestyles, that collective effort could send humans to the moon, that collective effort could dominate any other ferocious species that may have once scared them or that collective effort could lead them to a different, better future.</p> <p>Regardless of which scenario above is examined, it’s very likely that in each, we, <em>Homo sapiens</em>, may have been extinguished or conquered by a species that was capable of achieving that highly proficient level of mass coordination fueled by greedy-intolerant ambitions, similar to how we’ve sent countless other species to extinction by feeding on them or subverted other species like chimpanzees to zoos for entertainment and rats to laboratories for science. None other species, not elephants, nor bees, not chimps nor rats, who have indeed shown some level of mass cooperation, can organize themselves into such a succinctly designed assembly and be so well coordinated no matter how different they are like <em>Homo sapiens</em>. Let alone mention how other species other than <em>Homo sapiens</em> could have ambitions to improve their own situation, build intelligent machines, or explore outer space.</p> <p>All in all, the synchrony between intolerance and mass coordination sustained by a collective, intersubjective belief may sound unstable, but it’s this beautiful myth that constitutes part of the reason of why us humans, <em>Homo sapiens</em>, achieved our current status in history, which is in sharp contrast with other species such as Homo erectus or Neanderthals that have gone unreasonably extinct, or chimps and fish, that have become subverted by us without obvious reasons.</p> <h1 id="intolerance-and-mass-coordination-for-artificial-intelligence">Intolerance and mass coordination for artificial intelligence</h1> <p>On a completely different note, owed to my interest in AI, when reading about these fundamental aspects of humanity, it sparked in me an interest in how these aspects (mass cooperation, intersubjectivity, intolerance). Given the current progress in AI, we could ask intriguing questions as follows.</p> <blockquote> <p>How would AI look like if the different models that have achieved landmark achievements such as GPT-3 or AlphaFold were to merge or cooperate between one another, just like how humans from completely different civilizations worked together in human history? This chimeric model (<a href="#deus2">Figure 2</a>) would be capable of performing diverse tasks depending on the input that it perceives. These tasks may range from reading comprehension to protein structure prediction, to disease prognosis and autonomous driving.</p> </blockquote> <figure> <img src="/assets/img/homo-deus2.png" alt="Figure couldn't load due to an unknown error. Sorry."/> <figcaption id="deus2">Figure 2: schematization of the chimeric model meant to expand the current capacities of AI. This is done by, simply, merging the models that have achieved landmark results in the different competitions in a subfield of intelligence. </figcaption> </figure> <p>Of course, <a href="#deus2">Figure 2</a> is just a rough draft from which a plethora of practical concerns arise: how many models will it have to merge? What are the boundaries of each model added? Is this architecture scalable? Among others. Nonetheless, the underlying analogy to draw here is that just as how different humans can cooperate at a massive scale, I envision that the next step to get closer to general intelligence is to somehow be able to merge all these different models or to form certain connection among them.</p> <p>Harari has summarized quiet precisely that in biological terms, organisms’ sole purpose of existence is to survive and reproduce. Through natural selection, one species, like <em>Homo sapiens</em>, which is by nature intolerant and capable of achieving mass coordination through developing intersubjective believes, became the most powerful entity on Earth. Nonetheless, AI is not only not a biological entity, but also devoid of a purpose of existence. What are the “survive and reproduce”[^1] equivalents for AI, and how will AI evolve from those basic needs into also becoming “intolerant”, developing “intersubjective beliefs to massively coordinate” other AI models like the chimeric model in <a href="#deus2">Figure 2</a>, and subsequently displace <em>Homo sapiens</em> as the most powerful entity on Earth, or even larger, in the Milky Way or Universe. Therefore,</p> <blockquote> <p>… from another perspective, will we be able to embed in a machine a value function resembling the survival instincts of human beings, such that this value function can somehow guide the machine into evolving and developing complicated, yet intricate networks of machines to cooperate with one another into further enhancing this value function?</p> </blockquote> <p>With all the talk about AI above, it seems as if only we, <em>Homo sapiens</em>, shaped AI. Nonetheless, I believe we should be open to the idea that AI can also change us. For example, the pursuit of artificial intelligence has changed how we view intelligence, cognition, perception, among other mysterious human faculties that we don’t understand thoroughly, yet. AI, and its symbiosis with other sectors of society such as healthcare, education or economy will also have a deep impact in our lifestyles. Given this premise, we <em>Homo sapiens</em> can reflect on how our intersubjective realm is going to morph in response to how AI advances. Although Harari wasn’t specifically referring to AI, the following are quiet interesting ways to redefine some of the mysterious faculties we humans have:</p> <ul> <li>“feelings”: inaccurate term used to describe a collection of neuronal signaling. But then, I believe a natural question that follows then is what initiates this cascade of neuronal firing: external input, internal structure, or both?</li> <li>“Emotion”: a biochemical algorithm of neuronal signaling.</li> <li>“consciousness”: term to describe feelings and mental imagery (representation of our perception).</li> </ul> <p>Theoretically, this suggests that with a digital neural network, e.g. a deep neural network, that’s meant to simulate neural signaling would be able to model these human traits, even if the end result is not necessarily “within our expectations of what feelings, emotion and consciousness are”. For example, to me, the advances of image recognition have provided me with the following definition to “understanding”, which is to be able to have some higher level neurons fire probabilistically in response to the low level firing of neurons given an determined input stream. This is in sharp contrast with common definitions that advocates “understanding” assimilated a “meaning” that’s associated to an entity of the world, or somewhere along the lines. Of course, although there seems to be a more down-to-earth, precise, biological and mathematical definition to “understanding” that may be in contrast to a lot of our expectations (including me), it seems as though this is where we might be induced to think due to the rapid development of AI that’s going against much of the paradigms we believed in the past and present. As a side node, I’ll fervently encourage all of us to think not in tune with the current norms, since in this way we tend to reinforce our current paradigms, but rather to focus our studies and reflections on what’s different to the norm, since in this way we can explore and inquire into the unknown.</p> <p>It’s worth noting though that the above inquiries concerning the future development of AI revolves around our understanding of human beings, particularly <em>Homo sapiens</em>. Nonetheless, though <em>Homo sapiens</em> is very likely to be the dominant species in the world, it’s not the only one. The future steps could also draw some inspirations from other species as well. For instance, bats perceive the world through echolocation, so would this trait enhance AI?</p> <h1 id="but-in-the-end-are-we-happy">But in the end… are we happy?</h1> <p>I have attempted to share my thoughts on Yuval Harari’s two books on how we came to be as we are today (due to our intolerance to how we’re born and to those around us), as well as discussed where we might be heading, mainly by drawing parallels with the development of AI. However, just like author Harari, I wanted to ask, are we happy? As in, are we happy about with our current understanding of human nature? Are we happy about how we envision where we might be heading? These are some questions that dissolves itself into the abyss of neglect during our pursuit of understanding ourselves and of higher grounds of humanity.</p> <p>Of course, how do we define happiness to begin with anyway. Harari shared a simple definition, which is that happiness is a byproduct when our expectations meet reality, or vice-versa. We, <em>Homo sapiens</em>, have efficiently managed to survive until the present day, and through our intolerance to our previous selves, previous ways of living, we managed to climb to the top of the food chain and govern planet Earth. Nowadays, we’re in a crossroad where we get to decide to where we’re heading to, and whether the path chosen makes us happier, as in having our expectations driven by intolerance met, or make us more intolerant, as in having wilder, more ambitious expectations.</p> <p>The questions I’ll want to ask of course in this final section, given the plethora of possibilities that the understanding of human nature and progress in AI bring, are:</p> <blockquote> <p>Will our understanding of emotions and feelings help us become happier, or will it lead us to live in a society saturated by experiences such that there would be nothing else to make us happier?</p> </blockquote> <blockquote> <p>Will the symbiosis of AI with the different sectors of society (Healthcare, Economy, Education, among others) satisfy our needs or just produce even more needs?</p> </blockquote> <p>All in all, Sapiens and Homo Deus are two books authored by Yuval Harari that I highly recommend reading. Although both their themes don’t specifically revolve around artificial intelligence specifically, I’d also recommend wondering how our current understanding of <em>Homo sapiens</em> could shape the future development of AI. Of course, it’d be also fruitful to reflect on whether all this makes us become happier, or just makes us more ambitious to pursue happiness.</p> ]]></content><author><name>An Xuelong</name></author><category term="blog-post"/><category term="books-review"/><summary type="html"><![CDATA[my review on Sapiens and Homo deus, books authored by Yuval Harari]]></summary></entry><entry><title type="html">The Future of Medicine: Big Data and Democratization</title><link href="https://awxlong.github.io/blog/2021/topol-orig-tab/" rel="alternate" type="text/html" title="The Future of Medicine: Big Data and Democratization"/><published>2021-09-24T14:42:00+00:00</published><updated>2021-09-24T14:42:00+00:00</updated><id>https://awxlong.github.io/blog/2021/topol-orig-tab</id><content type="html" xml:base="https://awxlong.github.io/blog/2021/topol-orig-tab/"><![CDATA[<h1 id="overview">Overview</h1> <p>“Deep Medicine”<d-cite key="topol_2019_deep"></d-cite> and “The Patient Will See You Now”<d-cite key="topol_2015_the"></d-cite> are two books authored by Dr. Eric Topol in which he discusses the current challenges and future prospects of the merging of artificial intelligence and the healthcare sector. As always, I don’t seek to provide a summary of both books, but instead to provide some afterthoughts in the hope of igniting a fruitful discussion and inspiration in us for making the most out of the dynamic future, developing the capacities to overcome the difficulties and take advantage of opportunities that the coexistence of AI and humans bring in the diverse sectors of society.</p> <h1 id="current-challenges">Current challenges</h1> <p>Views can be polarized regarding the term “medicine” or “healthcare”. Pessimistic viewpoints tend to qualify it as the healthcare being a sector that tends to make profit from the patient, either though overprized medical tests that provide no useful insight to a patient’s status, expensive drugs unaffordable by low-income families, negative service offered by burnt-out doctors when seeing them and talking for just about 10 minutes without much empathy felt during the discussion, among others. Such situation can be summarized as “paternalistic medicine”, where the unknowing patient offers unconditional obedience to the doctor, which may prove inefficient for treating a disease as it may sometimes lead to an late-stage diagnosis of a disease (i.e. the patient comes to see a doctor at an advanced stage of a disease, say cancer, because he/she didn’t care about his/her health earlier), or high-cost, unnecessary expenditures (i.e. the healthy, yet unaware, patient undergoes expensive CT scans or X-rays that don’t provide meaningful information, all the while exposing him/her to too much radiation).</p> <p>I personally stand from a more optimistic perspective regarding healthcare, as I highly respect and admire the profession of medicine, and such view has been further reinforced through witnessing how healthcare workers, spanning from doctors to nurses, from radiologists to bioinformaticians, have fought bravely in the frontlines against the SARS-CoV-2 in order to safeguard the health of the common populace. I believe the above negative views over a burdened healthcare sector should not undermine the sacrifices of our healthcare personnel. Of course, that being said, my views still clash with the harsh reality of the current challenges in the healthcare sector, not only the ones above mentioned but also more, such as for instance misinformed patients who do not follow medical guidelines meant to improve their health (i.e. a smoking lifestyle that leads to pulmonary diseases or a high-carb diet despite having diabetes) which is a sign of a lack of communication and eventual empathic cooperation between doctor and patient.</p> <p>All the above, and more, have become obstacles for the democratization of medicine, which can be interpreted as a highly efficient, low cost healthcare sector that can serve for safeguarding the health of the majority of a population. And, indeed, as you may have guessed it, AI can help us solve such issues and achieve that.</p> <h1 id="ai-and-medicine-big-data-and-emancipation">AI and Medicine: Big Data and Emancipation</h1> <p>In “The Patient Will See You Now”, a recurrent theme has been exploiting the era of Big Data for empowering the patient with sufficient knowledge in order to make healthcare a more efficient interaction between doctor and patient. Different from the above described scenario, in the future, it’s expected that doctors will not unilaterally seek the unknowing patient to understand his/her health, but rather, the patient can readily visit the doctor and hold a more balanced/bilateral discussion about his/her health and, if required, the necessary treatment. This is thanks to the patient being equipped with enough knowledge of his/her own health status extrapolated from the understanding of own family history, genome tests, heart rate monitored through an own electrocardiogram, among other covariates that can be taken through cheap sensors that may be embedded in a smartphone, a symbol of the era of Big Data where each one of us can become data miners and make this data generated benefit each one of us (<a href="#self-test">Figure 1</a>).</p> <figure> <img src="/assets/img/self-patient.png" alt="Figure couldn't load due to an unknown error. Sorry."/> <figcaption id="self-test">Figure 1: Smartphones are expected to be embedded with a “laboratory on a chip (LOC)”. This allows for performing miniaturized lab tests or making these lab tests and their results portable. This opens the possibility of making disease diagnosis a way of life, and isn’t that the key to curing the majority of diseases? Images extracted from (left to right): https://threadreaderapp.com/thread/1076894405867462656.html, https://www.imedicalapps.com/2011/11/cardiodefender-mobile-ecg-diagnostic-system-accessed-smartphone/#, https://www.hearingreview.com/miscellaneous/oaktree-introduces-smartphone-enabled-digital-otoscope </figcaption> </figure> <p>Such a phenomenon has been called by Dr. Topol as the “emancipation” of the patient thanks to Big Data generated, owned and made useful by each one of us. Thus, what this big data can build for each individual is a personalized biological Geographic Information System (GIS) that spans from the exposome, epigenome, microbiome, metabolome, proteome, transcriptome, genome, anatome, physiome and phenome throughout one’s entire life. Indeed, this would constitute a panoramic view from pre-womb to tomb (<a href="#gis">Figure 2</a>).</p> <figure> <img src="/assets/img/human-gis.jpg" alt="Figure couldn't load due to an unknown error. Sorry."/> <figcaption id="gis"> Figure 2: The Human GIS cropped from The Patient Will See You Now. In the book, it’s estimated that the human GIS might oscillate around 10 TB of data </figcaption> </figure> <p>Among the opportunities that generating one’s own data brings is that an efficient and constant monitoring of one’s health status can help us achieve what may be the core of futuristic medicine:</p> <ul> <li> <p>Early detection: This is due to the patient equipped with enough cheap equipment materialized as sensors embedded in smartwatches or smartphones able to track different variables relevant to determine one’s health status. This could lead to at-home monitoring. Among the data that can be assessed, there is:</p> </li> <li>Tracking family history and genome data: it is to my believe that genome data may prove pivotal and become the next blockbuster in medicine. Not only does genome, coupled with family history, allow us to discover at an early stage a disease like cancer, there are other aspects regarding the human genome such as the transcriptome (RNA) or epigenome that further diversifies the amount of possibilities that can be taken advantage of in the early diagnosis of a disesase. Particularly, I’ve written about how miRNA, part of the human transcriptome, can serve as a disease and tissue-specific, non-invasive and cheap (when coupled with CRISPR-CAS system) diagnostic tool for the early detection of a disease like cancer and Alzheimer and also leaves a window of opportunities for becoming a therapeutic agent.</li> <li>Monitoring the gut microbiome: in order to understand how diet, and the gut microbiome’s composition shapes the health of the individual. This field is yet to be thoroughly understood.</li> <li>Tracking real-time health covariates: as said above, health factors like heart rhythm or blood glucose are expected to be more finely tracked and made useful by the patient through either micro-chips or bio-sensors which can provide useful data in a lot of aspects of healthcare other than the patient understanding his/her own health status, but also for instance, providing information about how a drug has interacted with molecules inside the body through these kind of biosensors, which influences its own design and delivery.</li> <li> <p>Even rare cases of disease can be early diagnosed as long as enough data is available. Throughout “The Patient Will See You Now”, Dr. Eric Topol discussed a consistent finding that about 3/4 of a sample of interviewees would be willing to make their anonymized medical records be publicly analyzable, since it’s for the benefit of the majority (and minority) of patients who may have share similar patterns or symptoms of a disease. What this leads to is what Dr. Topol has termed as Massive Online Open Medicine (MOOM) (an adaptation of Massive Online Open Course) that’s meant to harness your data, the data of people who surround you, and those who surround them, to build a database that can be used to crack from the simplest diagnoses to complicated, rare cases of disease.</p> </li> <li> <p>Early discussion: the emancipated patient can now seek expertise from the knowledgeable doctor instead of providing unconditional obedience. My opinion would be here in seeking balance, whereby being better equipped with medical data doesn’t mean undermining medical professionalism. For instance, in an special issue (issue 52) of The Batch, Dr. Topol mentioned how clinicians should spend their time talking to patients instead of staring at monitors and typing in electronic health records, since this could be done by AI, thus liberating them from this repetitive work. Thus, there shouldn’t be a replacement of the doctor, but rather a simplification of his/her load of work in order to allocate more time for doctor-patient face to face interaction.</p> </li> <li>Early treatment: which would become the best cure of a disease, as mentioned in a past blog.</li> </ul> <h1 id="ai-and-medicine-mutual-empathy">AI and Medicine: Mutual Empathy</h1> <p>Not far in the past I do acknowledge that I believed AI will sweep across the different fields of society, and in medicine it may well replace radiologists (sorting out X-rays), ophthalmologists (sorting out eye images), pathologists (sorting out tissue exams), cardiologists (diagnosing ECGs readings) or dermatologists (sorting out skin images). However, after reading “Deep Medicine”, I believe a more down-to-earth view is that, at least in the near future, AI can only serve as a helpful medical assistant that will help ease the burden on the mentioned medical professions, and not replace them. This is mainly because an important characteristic AI lacks is being holistic, or multitasking, a symbolic feature of narrow AI. A radiologist may not only examine X-ray images, he/she may also review the patient’s profile involving medical history, family history, or, perform even more diverse functions such as running and directing research teams, alleviating patient’s burden of their results, which requires emotional support, so all in all, this leaves AI the room of only becoming a very efficient virtual assistant that may very well alleviate the burden on doctor’s shoulders, on healthcare, and improve its efficiency during interaction with patients.</p> <h1 id="overcoming-todays-challenges-to-identify-tomorrows">Overcoming today’s challenges to identify tomorrow’s</h1> <p>Of course, despite having discussed the futuristic prospects of AI in the healthcare sector, reality is that there are still a lot of challenges to be overcome in order for an efficient merging of both sectors. Those that can be mentioned include:</p> <ul> <li>As Dr. Topol mentioned, there is already too much big data available, yet too little knowledge. This foreshadows the long road of mining all these data, subsequently process it and train efficient models, evaluate them and deploy them. For example, one such area in which a lot of knowledge is yet to be unthread is the human gut micriobiome and how it influences the host’s health; subsequently how would this knowledge be used by AI models to monitor patient’s health.</li> <li>However, model deployment in real life clinical settings is also a challenge: it’s already a daunting challenge to design machine learning algorithms used to process the available big data and train their respective models. Apart from this logistic hurdle, there are still ongoing trial and error, human-centered research seeking to identify and solve issues concerning developing a symbiotic relationship between a model and clinicians in real life settings<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup> <d-cite key="beede_2020_a"></d-cite>. For example, images of a retina fed into a model trained to diagnose diabetic retinopathy may have been of higher quality than retina images taken in a poorly equipped clinic, thus rendering the model unable to process these real-life inputs on site. This example thus exposes the difference in the pace in which developed countries progress in the field of AI &amp; Medicine, versus how the majority progress.</li> <li>Fundamentally, the merging of AI and medicine carries with it a different set of regulations and caution compared to, for instance, models deployed to predict user’s shopping preferences. It concerns the welfare, and maybe even life quality, of the user, thus there are barriers of skepticism to overcome before even adapting it to real-life. Ways to overcome such obstacles can be through more rigorous, longitudinal evaluations, such as the golden standard for empirical evidence gathering, randomized control trials for AI models in medicine <d-cite key="kelly_2019_key"></d-cite>. It’s worth noting here that there are already randomized trials that demonstrate the utility of AI. For example, Chinese researchers have shown that deep neural networks can identify lesions missed by gastroenterologists during endoscopy and colonoscopy <d-cite key="topol_2019_it"></d-cite>.</li> <li>Another way to address issues concerning regulations surrounding AI is the development of self-explanatory AI (also named X-AI)</li> <li>Of course, impact in lifestyle, as well as sociocultural implications of AI models intervening in healthcare should also be addressed, with issues such as data privacy to safeguard one’s GIS, or democratization of medicine echoed by Dr. Topol throughout his books.</li> </ul> <p>A particular example that struck me when reading “The Patient Will See You Now”, is that by the year 2015 when this book was published, it was mentioned that there existed a company startup called Theranos. This company had the innovative idea of providing affordable and portable diagnostic tests for a lot of diseases using just a blood sample from the patient. This seemed to promise a lot of potential. However, years later it turned into a defunct company for allegations of fraud<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup>. We can learn from this real world case scenario that although the merging of AI and Healthcare is very attractive, promising and revolutionary, we should still retain our senses of skepticism, caution and honesty when materializing such potentials.</p> <h1 id="final-remarks-on-ai-and-healthcare">Final remarks on AI and Healthcare</h1> <p>As mentioned throughout the text, the merging of AI and the Healthcare sector can be thought be revolutionary, and it’s going to drastically change our lives. It may redefine the patient-doctor relationship, such as emancipating the patient with data while liberating the doctor from burden. Of course, perhaps a logical question that follows is when can we witness such a change? In my opinion, that day may come sporadically. We might transition through phases, instead of changing fundamentally our lifestyle in an instant. Although it’s true that part of the population of certain countries is already using smartwatches and smartphones to monitor health biomarkers like heart rate, we are still far from exploiting the full potential of our devices that has been mentioned throughout the text.</p> <p>All in all, as long as we’re able to face the challenges brought by medicine and AI, we can grasp perhaps unlimited potential from its symbiotic relationship. In the future, we may be able to save lives without even having to touch the scalpel or perform surgeries. Most diseases could be prevented through daily monitoring of health. Perhaps medicine will not only teach us the technicalities of anatomy, pharmacology, or biology, but also focus on the empathic relationship between the patient and doctor. This is because our devices, our machines, can perform diagnosis at a (maybe) more accurate rate and accumulate far more information than a human can (funnily, our machines can go through med school for us). What do you think will happen? How do you plan to address the future challenges and opportunities? What do you expect from AI and Healthcare?</p> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:1" role="doc-endnote"> <p>Case study from special issue 52 of The Batch (you can subscribe to a mailing list): https://www.deeplearning.ai/thebatch/?utm_campaign=The%20Batch&amp;utm_medium=email&amp;_hsmi=87523675&amp;_hsenc=p2ANqtz-9Bz_mGy2bjkmt-GvaSVleiSgwrPPkDCcCiSgjQ2zZD18RIeRcVpmHfmy-KCGBrl0PNOJun&amp;utm_content=87523675&amp;utm_source=hs_email <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:2" role="doc-endnote"> <p>Please consult: https://www.msn.com/en-gb/news/world/disgraced-theranos-ceo-to-blame-mental-illness-in-her-fraud-trial-defence/ar-BB18V45b <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> </ol> </div>]]></content><author><name>An Xuelong</name></author><category term="blog-post"/><category term="books-review"/><summary type="html"><![CDATA[review on Deep Medicine and The Patient Will See You Now, two books authored by Dr. Eric Topol]]></summary></entry><entry><title type="html">Saving the Future: Comment on AI·Future (AI·未来) and Artificial Intelligence (人工智能)</title><link href="https://awxlong.github.io/blog/2021/kaifu-toc/" rel="alternate" type="text/html" title="Saving the Future: Comment on AI·Future (AI·未来) and Artificial Intelligence (人工智能)"/><published>2021-08-06T15:42:00+00:00</published><updated>2021-08-06T15:42:00+00:00</updated><id>https://awxlong.github.io/blog/2021/kaifu-toc</id><content type="html" xml:base="https://awxlong.github.io/blog/2021/kaifu-toc/"><![CDATA[<h1 id="aifuture-ai未来-and-artificial-intelligence-人工智能">AI·Future (AI·未来) and Artificial Intelligence (人工智能)</h1> <p>AI·Future (AI·未来) <d-cite key="kaifulee_2018"></d-cite> and Artificial Intelligence (人工智能) <d-cite key="kaifulee_2017_ren"></d-cite> are both books written by Professor Kai-Fu Lee, the latter co-authored with Yong Gang Wang, that talks about the current and future challenges and opportunities brought by Artificial Intelligence. I don’t pursue providing a summary of both books, but rather contribute my afterthoughts on them hoping to inspire you to maybe skim or read thoroughly both of them in order to share ideas regarding how humanity shall cope with the benefits and dangers that AI will present to us in the near future. It’s meaningful for trying to cope with the deep changes caused by AI that are going to permeate into our daily lives.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/weilai.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Cover of the book AI·Future (AI·未来) by Kai-Fu Lee。 </div> <h1 id="narrow-ai-vs-general-ai-the-future-of-ai-progress">Narrow AI vs. General AI: the future of AI progress</h1> <p>A common starting point to address AI might be establishing with what perspective to view AI. Given the influence of fictitious movies and novels, it might be worth pointing out some of the exaggerations regarding the current and near-future progress on AI. Despite since 2012 with the release of Prof. Geoffrey Hinton’s paper about Deep Learning[1] which has “revolutionized” the field of AI, such optimistic environment has also morphed into fear given that AI may one day surpass humans in every task we do, with such worry being augmented by how Alpha-Go defeated the world champion in the game of Go, with books like Superintelligence by philosopher Nick Bostrom or predictions made by Prof. Stephen Hawking regarding a dystopian future caused by AI. However, from the point of view of Kai-Fu Lee, such incidents should be addressed cautiously and without spreading unnecessary fear.</p> <p>Yes, AI is advancing very rapidly, with achievements such as being better at image recognition than humans across different fields such as in that of security or medicine, predictions in the field of economics or simulating physical phenomena, among others. This holds true especially given the extraordinarily amount of training data that is being generated which will be able to further train neural networks at much more diverse tasks. Nonetheless, it’s worth pointing out that such AI shouldn’t be the source of fear given how limited is the task it can perform, i.e., Alpha Go can defeat the world champion in Go, but definitely can’t at the same time generate a short poem, a convolutional neural network can excel radiologists in identifying, say, a pulmonary disease like pneumonia, but it can’t simultaneously device a therapeutic strategy to deal with such disease like a doctor would. All in all, AI still cannot perform tasks across fields, or do multitasking, which means that it is still what’s commonly known as narrow AI. Given such premise, a fundamental idea that has put forward is to not fall down into ungrounded panic that may result in the halting of study of AI in order to prevent a perceived destruction of humanity (a sort of subconscious self-preservation bias).</p> <p>Kai-Fu Lee did point out what narrow AI still lacked in order to turn into general AI:</p> <ul> <li> <p>Cross-domain reasoning: as stated above, for narrow AI to become general AI, then it shouldn’t be task-specific, or task-oriented, given that it should be able to not only “solve” problems when indicated, but maybe also “study” in its spare time, “come up” with a new recipe that hasn’t been created, “predict” the weather or the next natural catastrophe, device a strategic plan to counteract such, among others. However, it may be a long road before such feat is achieved, given that another breakthrough in AI might be required.</p> </li> <li> <p>Abstract reasoning: deep learning can be thought of as fundamentally “performing isomorphic transformations to a set of input vectors or matrix in order to map them to a probability distribution to get an output”. However abstract reasoning might be something fundamentally different than this; how is it that our minds can create and device analogies, such as in Chinese, relating the number 8 to wealth, or generate creative works that help you memorize the periodic table through a song? This and other lingering questions.</p> </li> <li> <p>Know “what’s the result” and knowing “why”: though there are advance in explainable AI in explaining why do some neural networks output certain results, when humans think about the “why something happened” concerns the establishment of causal relationships, which although AI lacks to some extent, it’s a field that has seen progress in solving.</p> </li> <li> <p>Common sense and self-consciousness: I do share the same idea with Kai-Fu Lee about AI lacking these features we humans have, and I do admit I can’t make further comments on them given that they are probably nativist features that has accompanied humans since birth. Whether they can be “given” or “gained” by AI is a mystery to me, which furthers the above viewpoint of narrow AI being unnecessary in stirring up panic.</p> </li> <li> <p>Aesthetics</p> </li> <li> <p>Emotion: Kai Fu Lee has a personal experience that has led him to believe that despite AI becoming smarter and smarter, it might never replace humans in the field of having emotions. A life anecdote of his is that in the past he once had stage IV lymphoma, whom after undergoing the necessary operation and surviving, started reflecting about his own life and started noticing that because he has been a workaholic through most of his life he has been neglecting his wife and children, which in turn catalysed in him profound changes from being an entrepreneur and computer scientist, to becoming a good husband, son and educator who could witness what we commonly know as “love”.</p> </li> </ul> <p>Laying out the above cards on the table, I just want to help, like Kai-Fu Lee, relieve some of the unnecessary worries regarding AI, because when talking about such some lingering questions may arise such as ”can AI also undergo such a meaningful reflection about itself and go through a meaningful change to become a more kind AI?”. There may be the case that AI can replace the human brain as it expands its horizon of tasks able to be solved, but it cannot replace the human heart, being such a complex and dynamic thing.</p> <h1 id="artificial-intelligence-and-the-future-of-businesses-opportunities-and-challenges">Artificial Intelligence and the future of businesses: opportunities and challenges</h1> <p>Despite trying to appease excessive panic, this does not mean that I seek to spread absolute negligence towards the development of AI and its impact to our daily lives. It’s unnecessary panic that should be avoided, but rational cautiousness is more than well invited from the reader in order to aid the future humanity in solving the possible crashes that can happen between AI and humans, particularly in the business sector in terms of jobs. Without inquiring too deep into the undoubtly benefits that AI can bring in terms of rising economy thanks mainly to the rise of efficiency, perhaps what’s more important is to address the impact on jobs lost and the resulting inequality in welfare.</p> <p>As a brief summary, please examine <a href="#job">Figure 1</a> I extracted and translated from Kai-Fu Lee’s book AI·Future where jobs that may be secured and lost in the future are displayed on a basis of technicality of such job, and the degree of social interaction. Technicality here refers to the degree in which the job can be mechanized or structured, for example, a cardiologist is a highly technical job that’s difficult to be mechanized or structured given that a cardiologist must learn how to diagnose a disease by being a data scientist able to swiftly manipulate electronic health records, perform surgeries and may also be trained in relieving the emotional burden of the patient, so such cross-domain reasoning involving the use of emotions is currently very difficult for AI to simulate, while on the other extreme a job that requires highly repetitive steps (i.e. easily mechanized) and doesn’t involve much social interaction, like a truck driver, can be easily replaced by AI.</p> <figure> <img src="/assets/img/job-prospects.png" alt="Figure couldn't load due to an unknown error. Sorry."/> <figcaption id="job">Figure 1: Coordinate System translated from Kai Fu Lee’s book AI · Future. It displays jobs that may be secured, must merge with AI, lost or have to undergo changes to adapt to the future. The x-axis represents the degree of technicality and difficulty in being mechanized, while the y-axis represents the degree of social interaction of such job. </figcaption> </figure> <p>From the graph above, an immediate advice would then be to at least lay down the following foundations in order to secure jobs in the future:</p> <ul> <li> <p>The learning of programming skills in order to develop the capabilities required to analyse data or develop software that may be required by jobs that fully or has partially adapted AI.</p> </li> <li> <p>The learning of social skills in order to not only make the above programming skills useful for a community through being down-to-earth, but also because jobs that require human-to-human interaction can those jobs lost due to human-to-object interactions mechanized by AI.</p> </li> </ul> <p>But of course, awareness arising from oneself is not enough to curb the problems brought by AI in the business sector, rather, the interplay of key members and institutions of society; this is all in order to avoid the catastrophic welfare inequality that may arise otherwise. Kai-Fu Lee pointed out four entities that will shape the era of AI:</p> <ul> <li> <p>Big Data: something to be pointed out is that although the rate of generation of data has augmented over the years, the rate of analysis of such data, that is, the generation of knowledge, hasn’t kept up. In the era of AI, hence, to truly make such data useful, then a thorough processing of such directed at solving issues in society, be it healthcare or in the business sector, is needed.</p> </li> <li> <p>Entrepreneurs: perhaps it’ll be in the creative minds of entrepreneurs on coming up with novel ideas of futuristic jobs, of course bearing in mind the pursuit of the over-all, long term welfare of a society as a whole instead of a short term accumulation of welfare that will exacerbate social instability.</p> </li> <li> <p>Scientists</p> </li> <li> <p>Government and Policy Makers: in the future, perhaps the core of policy makers shouldn’t be devising policy to ensure the equal distribution of resources, akin to partitioning a cake equally to a group of people, but rather create and ensure an environment that allows the opportunities for the production of more resources to be vibrant, akin to making such cake bigger for a larger group of people together.</p> </li> </ul> <p>Prof. Kai-Fu Lee also shared some ideas regarding where the focus for the generation of future jobs is. It is unlikely to witness the next breakthrough after deep learning in AI in the near future, hence the creation of an innovative service or product should be built upon on the basis of how to mostly exploit the technique of deep learning along with existing big data (of course, this is not to undermine the pursuit of the next breakthrough in AI); such product should be:</p> <ul> <li> <p>Down-to-earth: that is, using the enormous amount of available data, build a model that can solve current and future issues of society instead of just simply breaking a record in certain game or defeating a very well-known player; instead, for such product to flourish, it should solve concerning issues that has been noticeable, for instance, during the COVID-19 pandemic, be it in the healthcare sector (how an AI can improve real-time diagnosis and health monitoring) or education sector (how AI can aid widespread good quality education that can be available online to ensure learner’s safety and health).</p> </li> <li> <p>Localized to a society. For instance, in a country such as China, which houses a civilization with a distinct customs and culture, how can a service or product be designed in such a way that’s well amalgamated to such civilization. An example of such is the difference between the search engines Baidu and Google. In Baidu, whenever you click on a link, a new tab is opened to display such webpage, while in Google the link is opened in the same tab. Such slight difference respects the customs of Chinese wanting to be able “to explore multiple webpages whilst still having the menu without being kicked out”, which is different from Google users who tend to focus on the same webpage hence don’t require to return to the menu. How can more products or services in the era of AI, with finely tuned subtleties adapted to a particular society, help solve the unemployment issue more efficiently than blindly creating a new product or service?</p> </li> </ul> <h1 id="ai-and-human-self-understanding-the-future-of-philosophical-reflection-of-human-nature">AI and human self-understanding: the future of philosophical reflection of human nature</h1> <p>Kai-Fu Lee in his books, as well as in his TED Talk “How AI can save our humanity”, has constantly mentioned how after having recovered from his cancer, his views about life and AI have changed dramatically, particularly because he saw in his transition towards paying more attention to his family, be it wife, daughters and aging mother, as well as the conversion from a machine-like, cold hearted workaholic to a passionate educator guiding the next generation on how to properly address the problems of AI, a human quality that may never be modelled, hence never be surpassed, by AI. Whether it is called “passion”, “love” or the “longing for life” or “wish for good health”, these are all perhaps features that may become access points towards a further understanding of ourselves. Such a reflection may inspire the future generation to become more vivid in questioning themselves given that through the development of AI, not only has our understanding of machine intelligence improved, but also that of ourselves.</p> <p>That is, when AI learns to become more and more similar to humans, it’ll be our mission to find out in what else are we different. In the search for perfecting AI, we might learn to understand us better. Perhaps AI can help us answer the question that has accompanied humans for eternity: What is the purpose of life?</p> <h1 id="our-contribution-to-saving-the-future-innovative-ideas-for-futuristic-jobs">Our contribution to saving the future: Innovative ideas for futuristic jobs</h1> <p>Whether you intend to become a data scientist, policy maker, entrepreneur, artist, among other professions which may seemingly appear unrelated to each other, we can all contribute with our ideas on how to advert the challenges brought by AI while making the most out of this new era. In the end, just as Prof. Kai-Fu Lee pointed out, it’s perhaps inaccurate to say that what has been said might occur in the near or far future… the future is “NOW”.</p> <p>After sharing the above, the following is an expanding list of possible jobs that may serve in curving the unemployment caused by AI; your ideas are expected to further enlarge the list:</p> <ul> <li> <p>Data miner (profession): for those who are familiar with deep learning, it is very well known that to train a network, a great amount of data is required. Although it has been repeatedly mentioned that there is already a lot of unprocessed data, some businesses may still require data that just has too many specific qualities, hence requires the hiring of data miners to collect data of such characteristics. For instance, to build driverless cars, a lot of data concerning videos of road infrastructure, stop signs, lights, pedestrians, among others, must be collected.</p> </li> <li> <p>Data labelers (profession): following from the above, data labelers should become a profession in order to develop an AI software.</p> </li> <li> <p>Waiter serving food on driverless limousine/restaurant (profession): to compensate for the drivers that may lose their jobs due to driverless cars, they can be retrained to follow another profession like a waiter and turn their driverless cars into a dynamic, small scale restaurant.</p> </li> <li> <p>Small diagnostic device that takes in a drop of blood with certain miRNA configuration in order to predict the risk of developing cancer (product): this has been an idea shared in a previous post, called “DeepMiRNA: miRNA as therapeutic targets”</p> </li> <li> <p>An application that takes as input your notes taken from a lecture and outputs an interactive game to help you memorize them (product): the idea is to make notes taken from a lecture as addictive as someone is to a famous game.</p> </li> <li> <p>What ideas do you have?</p> </li> </ul> <p>In the end, if you are interested in artificial intelligence and its impact on humanity, then you are more than welcomed in reading Prof. Kai-Fu Lee’s books as well as many others.</p> ]]></content><author><name></name></author><category term="blog-post"/><category term="books-review"/><summary type="html"><![CDATA[my review on two books AI·Future (AI·未来) and Artificial Intelligence (人工智能) authored by Dr. Lee Kai-Fu.]]></summary></entry></feed>