<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://awxlong.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://awxlong.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-10-03T13:43:29+00:00</updated><id>https://awxlong.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">CureSeek: Quantized LLM Therapeutic Agent</title><link href="https://awxlong.github.io/blog/2025/cureseek-therapeutic-agent/" rel="alternate" type="text/html" title="CureSeek: Quantized LLM Therapeutic Agent"/><published>2025-08-31T15:42:00+00:00</published><updated>2025-08-31T15:42:00+00:00</updated><id>https://awxlong.github.io/blog/2025/cureseek-therapeutic-agent</id><content type="html" xml:base="https://awxlong.github.io/blog/2025/cureseek-therapeutic-agent/"><![CDATA[<h1 id="cureseek-therapeutic-agent-code-for-cure-bench">CureSeek Therapeutic Agent: Code for CURE-Bench</h1> <p>We participated in the <a href="https://www.kaggle.com/competitions/cure-bench">CURE-Bench competition</a> on therapeutic reasoning via external tool usage with LLMs, and we open-source our code at https://github.com/awxlong/cureseek_therapeutic_agent.</p> <p>Our approaches emphasizes affordability on low computational budget:</p> <ol> <li> <p>We first tried supervised-finetuning a Qwen-distilled, quantized <a href="https://www.kaggle.com/models/deepseek-ai/deepseek-r1/transformers/deepseek-r1-distill-qwen-1.5b">DeepSeek-R1</a> of 1.5 billion parameters. The competition has no training data, and the validation data has no reasoning traces before arriving to an answer. We annotated validation data by using both quantized <a href="https://huggingface.co/mradermacher/TxAgent-T1-Llama-3.1-8B-GGUF">TxAgent</a> and prompting DeepSeek-R1-distill-qwen-1.5b to explain how to arrive at the correct answer for questions in the validation set. Please see <a href="experiments/self_correction_deepseek.py">experiments/self_correction_deepseek.py</a> where we perform batch inference of input validation data.</p> <ol> <li>This augmented validation set was treated as our ‘training’ set to fine-tune a base DeepSeek-R1-distill-qwen-1.5b, and the code is in <a href="experiments/sft_deepseek.py">experiments/sft_deepseek.py</a>, and the supervised finetuning pipeline is mainly elaborated upon https://www.kaggle.com/code/danielphalen/grpotrainer-deepseekr1. This approach didn’t seem to work. Inference with base DeepSeek-R1-distill-qwen-1.5b yielded higher test score, suggesting fine-tuning may have impaired its internal reasoning.</li> </ol> </li> <li> <p>We next tried simply performing inference with quantized TxAgent, which yielded a score close to the competition’s baseline of $0.5$. Please check <a href="experiments/quantized_txagent_inference.py">experiments/quantized_txagent_inference.py</a>. The code is written to support multiprocessing to speed up inference on Kaggle.</p> <ol> <li> <p>Inference with quantized TxAgent leads to many <code class="language-plaintext highlighter-rouge">No answer</code> entries as the model requires external tools to find out more information about novel drugs, their contraindications, their recommended dosage, among others, prior to inferring an answer. Nonetheless, because we are constrained by computational budget, we aimed at keeping answers within $2048$ tokens, so we didn’t use the original <a href="https://github.com/mims-harvard/TxAgent">TxAgent</a> which is very, very computationally expensive (e.g. recommended H100 GPU usage with more than 80GB of memory and maximum tokens of $&gt;90000$).</p> </li> <li> <p>To keep inference affordable, we needed to feed information on drugs that TxAgent didn’t know about. To do this, we first use the above DeepSeek-R1-distill-qwen-1.5b to extract relevant drug entities in the test questions; please check <a href="experiments/entity_extraction_deepseek.py">experiments/entity_extraction_deepseek.py</a>. We use the extracted entities to construct (complex) queries which can be used to retrieve information about drug entities from the European PMC and PrimeKG; please check <a href="experiments/rag_context_augmentation.py">experiments/rag_context_augmentation.py</a>.</p> </li> <li> <p>The extracted information served as ‘augmented’ context to do RAG-based inference for a second time on ‘No answer’ entries using quantized TxAgent with <a href="experiments/quantized_txagent_inference.py">experiments/quantized_txagent_inference.py</a>. This raised the test score a little bit. We didn’t have enough time anymore, so for remaining <code class="language-plaintext highlighter-rouge">No answer</code> entries we simply filled them in via similarity-based semantic search using Qwen2-1.5B-instruct. This consists of extracting embeddings of the partial answer of quantized TxAgent, then measuring its cosine similarity with each of the MCQ answers and outputting the one with the highest similarity. This raised the final test score accuracy to $0.42$; please check <a href="semantic_search.py">semantic_search.py</a>.</p> </li> </ol> </li> </ol> <p>We are wondering whether there exists a very simple solution to this complicated CURE-Bench benchmark, perhaps by simply doing online RAG (searching Google via an API), and then using a quantized TxAgent to reason over the search results…</p>]]></content><author><name>Xuelong An</name></author><category term="blog-post"/><category term="research"/><summary type="html"><![CDATA[my code for the CUREBench competition on training LLMs for therapeutic reasoning via external tools]]></summary></entry><entry><title type="html">On thoughts about the Master Algorithm</title><link href="https://awxlong.github.io/blog/2025/master-algorithm/" rel="alternate" type="text/html" title="On thoughts about the Master Algorithm"/><published>2025-06-15T13:56:00+00:00</published><updated>2025-06-15T13:56:00+00:00</updated><id>https://awxlong.github.io/blog/2025/master-algorithm</id><content type="html" xml:base="https://awxlong.github.io/blog/2025/master-algorithm/"><![CDATA[]]></content><author><name></name></author><category term="blog-post"/><category term="food-for-thought"/><summary type="html"><![CDATA[I share five different paradigms of modelling intelligence]]></summary></entry><entry><title type="html">Gramática universal y una gallina</title><link href="https://awxlong.github.io/blog/2025/luis-UG/" rel="alternate" type="text/html" title="Gramática universal y una gallina"/><published>2025-04-25T13:42:00+00:00</published><updated>2025-04-25T13:42:00+00:00</updated><id>https://awxlong.github.io/blog/2025/luis-UG</id><content type="html" xml:base="https://awxlong.github.io/blog/2025/luis-UG/"><![CDATA[<p><em>Declaración: DeepSeek ha sido usado para asistir en la escritura de este artículo y navegación de bibliografía.</em></p> <p>A continuación quisiera compartirles una serie de observaciones con el fin de iniciar una serie de discusiones que conciernen a la naturaleza del lenguaje humano.</p> <p>El escritor, poeta y cuentacuentos Julio Cortázar publicó “Historias de cronopios y de famas” (1962), una obra lúdica y surrealista que juega con el lenguaje y las convenciones literarias. En esta, hay un cuento muy interesante escrita de esta manera:</p> <h3 id="por-escrito-gallina-una">Por escrito gallina una</h3> <p>Con lo que pasa es nosotros exaltante. Rápidamente del posesionadas mundo estamos hurra. Era un inofensivo aparentemente cohete lanzado Cañaveral americanos Cabo por los desde. Razones se desconocidas por órbita de la desvió, y probablemente algo al rozar invisible la tierra devolvió a. Cresta nos cayó en la paf, y mutación golpe estamos de. Rápidamente la multiplicar aprendiendo de tabla estamos, dotadas muy literatura para la somos de historia, química menos un poco, desastre ahora hasta deportes, no importa pero: de será gallinas cosmo el, carajo qué.</p> <p>Fin</p> <p>Aunque la gramática presente en el texto parece errática, nuestra mente puede atribuir significado al texto y construir una historia. De hecho, el juego linguístico que Julio Cortázar nos invita es explorar cómo la gallina cobra vida y empieza a actuar a medida que la historia avanza.</p> <h2 id="relación-con-gramática-universal">Relación con gramática universal</h2> <p>Leer este texto me ha causado la curiosidad de explorar su relación con gramática universal. Esta es una teoría propuesta por el Prof. Noam Chomsky, la cual discute que el lenguaje humano es una capacidad innata que nos permite generar oraciones aplicando reglas universales que son recursivas. Según mi interpretación, nosotros los humanos podemos anclar símbolos arbitrarios a objetos que existen en la naturaleza, como la palabra “gallina” con una gallina. Hay una jerarquía de símbolos, en la cual en la escala principal existe un sujeto, la cual puede ser descrito por sus propiedades y cómo estas cambian, o sea, adjetivos, adverbios o verbos. Aplicando las reglas universales, podemos imginar un sin-número de situaciones en la cual la gallina puede estar sujeta.</p> <p>Sin embargo, la rigidez de estas reglas se contrasta con la fluidez la cual Julio Cortázar narra su cuento. Analizar esta (aparente) dicotomía podría ayudarnos a entender un paso qué es el lenguaje humano.</p> <h2 id="preguntas-abiertas">Preguntas abiertas</h2> <ul> <li> <p>¿Qué opinas de la relación entre el juego semiótico de Julio Cortázar con las reglas formales de Noam Chomsky?</p> </li> <li> <p>¿Cómo el símbolo es anclado a su significado? ¿Cómo la mente lo ancla?</p> </li> </ul> <p>Finalmente, les comparto un cuento generado por DeepSeek al estilo no convencional de Julio Cortázar:</p> <p>Por escrito un tomate</p> <p>Con lo que pasa es nosotros electrizante. Fuerte el sol pegaba en huerta la cuando cayó del cielo eso. No meteorito ni basura espacial era, no: tomate un perfecto, rojo tan que casi falso parecía. Lo recogió abuela la y “esto no normal es” dijo, pero ensalada la en lo cortó igual.</p> <p>Error grave.</p> <p>Primero los pepinos empezaron a cantar boleros. Después las cebollas se declararon en huelga y se negaron a hacer llorar. La lechuga se puso filosófica y discutía de Sartre con los rábanos, que de nihilistas tenían un poco pero sabrosos seguían siendo.</p> <p>Abuela mi se volvió loca de remate. “Basta ya” gritó y al tomate lo escupió, pero tarde era: las palabras de ella en el aire quedaron flotando, visibles como nubes de tinta. “Maldita sea” escribió el perejil en el suelo con sus raíces.</p> <p>Ahora todo el pueblo come versos. El panadero vende sonetos crujientes, el carnicero filetes de haiku. Yo intento protestar pero mis vocales se deshacen en la boca, ácidas. El tomate ríe desde frutero el, semillas sus son comas y puntos suspensivos.</p> <p>Qué sé yo. Literatura de digestión difícil.</p> <p>FIN</p> <p>Me costó algunas iteraciones ingeniando prompts debido a que DeepSeek tiende a “corregir” el estilo no-convencional de Julio Cortázar.</p>]]></content><author><name></name></author><category term="blog-post"/><category term="food-for-thought"/><category term="class-notes"/><summary type="html"><![CDATA[una serie de observaciones y preguntas interesantes que conciernen al lenguaje humano.]]></summary></entry><entry><title type="html">Goedel Benchmarks: self-improving benchmarks</title><link href="https://awxlong.github.io/blog/2025/benchmarks/" rel="alternate" type="text/html" title="Goedel Benchmarks: self-improving benchmarks"/><published>2025-03-15T12:42:00+00:00</published><updated>2025-03-15T12:42:00+00:00</updated><id>https://awxlong.github.io/blog/2025/benchmarks</id><content type="html" xml:base="https://awxlong.github.io/blog/2025/benchmarks/"><![CDATA[<h1 id="on-the-leaderboard-illusion">On the Leaderboard Illusion</h1> <p>For many conceivable scenarios where we face the dilemma of deep learning model choice for deployment, we would entourage around an authoratitive benchmark to compare the performance of different models on it. For example, in the realm of large language models (LLMs), their language comprehension is thoroughly evaluated by a benchmark suite, including the <a href="https://lmarena.ai/">Chatbot Arena</a>, where users can freely chat with a pair of anonymous LLMs and rate how good are their responses. A high “scoring” LLM on the benchmark can thus serve as the cornerstone of trust which we confide on to deploy it within a real-world application.</p> <p>Nonetheless, as time passes by, new challenges arise. The issue with these (centralized) reputable benchmarks is that they invite practices of metric-hacking. Taking Chatbot Arena as an example, the study “The Leaderboard Illusion”, authored by Shivalika Singh et al., pointed out how such a challenging benchmark can be permeated with practices which inflate a LLM’s performance, including but not limited to forms of <em>overfitting to the benchmark’s distribution.</em></p> <p>There are many fixes proposed in the literature to address the problems, such as testing on multiple benchmarks instead of relying on a monolith “gold standard”, or disclosing evaluating practices so that the community can better judge a model’s performance by understanding how it was evaluated. In addition to the aforementioned, we propose the concept of a <strong>“Goedel Benchmark”</strong>, a self-improving benchmark which becomes more challenging over time. This idea of self-reference stems from a paper written by Prof. Schmidhuber regarding the design of self-improving problem solvers.</p> <p>A Goedel Benchmark differs from current benchmarks in that it has no static training-testing distributions, thus mitigating issues driven by metric-hacking which opens the possibility to overfitting to the test distribution. This can be achieved by a method discussed in a previous article where a benchmark consists of:</p> <ul> <li>some generator which generated challenging tasks</li> <li>the solver (the model being evaluated) which solves the task and feeds it to the generator</li> <li>in this way, the generator learns to generate more challenging problems over time.</li> </ul> <figure> <img src="/assets/img/feedback_loop.png" alt="Sorry. Image couldn't load." width="100%" height="auto"/> <figcaption id="cell-embedder">Illustration of the feedback loop between problem-solver and problem-generator </figcaption> </figure> <p>This benchmark is “dynamic” in that it’s not a closed set of question-answers. Rather, its current set of problems (and the solutions proposed by evaluated models) evolve tangentially to each other. The Goedel Benchmark also draws inspiration from Prof. Stanley’s “novelty” search, in that it evolves without a fixed direction, instead renewing itself with each iteration to stay perpetually innovative. In this regard, it’s not per se “accurate” to describe the benchmark grows to be more “challenging”, rather, it grows to be more “novel”. Said otherwise, each new iteration of the benchmark simply becomes distinguishable with prior iterations.</p> <p>Finally, since a Goedel Benchmark is not static, performance in it can not be conveyed by a single metric. Instead, we resort to <strong>trends</strong> to represent a model’s performance on a Goedel Benchmark, where a “positive” trend (i.e. a model which can solve more challenging problems over time) can be considered by the community as a high-performing model.</p> <h1 id="bibliography">Bibliography:</h1> <ol> <li> <p>Schmidhuber, J. (2003). Goedel Machines: Self - Referential Universal Problem Solvers Making Provably Optimal Self - Improvements. arXiv. https://arxiv.org/pdf/cs/0309048</p> </li> <li> <p>Singh, S., Yang Nan, Y., Wang, A., D’Souza, D., Kapoor, S., Ustun, A., Koyejo, S., Deng, Y., Long Pre, S., Smith, N., Ermis, B., Fadaee, M., &amp; Hooker, S. (2025). The Leaderboard Illusion. arXiv. https://arxiv.org/pdf/2504.20879?context=stat</p> </li> <li> <p>Stanley, K. O., &amp; Lehman, J. (2015). Why greatness cannot be planned: The myth of the objective. Switzerland: Springer International Publishing AG Switzerland.</p> </li> </ol> <p>Any comments? Feedback?</p>]]></content><author><name>Xuelong An</name></author><category term="blog-post"/><category term="research"/><summary type="html"><![CDATA[we propose that rigorous evaluation of deep learning models through benchmarks can draw inspiration from Prof. Schmidhuber's Goedel Machines, i.e., self-improving benchmarks which report trends, not scores, as measures of performance.]]></summary></entry><entry><title type="html">A brief take on benchmarks</title><link href="https://awxlong.github.io/blog/2025/arc/" rel="alternate" type="text/html" title="A brief take on benchmarks"/><published>2025-02-08T12:42:00+00:00</published><updated>2025-02-08T12:42:00+00:00</updated><id>https://awxlong.github.io/blog/2025/arc</id><content type="html" xml:base="https://awxlong.github.io/blog/2025/arc/"><![CDATA[<h1 id="on-the-theory-laden-nature-of-benchmarks">On the theory-laden nature of benchmarks</h1> <p>Francois Chollet published the <a href="https://github.com/fchollet/ARC-AGI">Abstraction and Reasoning Corpus</a> (ARC) on 2019 as part of his paper about the Measure of Intelligence. Intelligence should not be understood as achieving a high performance on some task or solving a problem like computer vision or language understanding benchmarks. Rather, intelligence should be understood as the ability to acquire skills to solve problems.</p> <figure> <img src="/assets/img/arc.png" alt="Sorry, an unanticipated error occured and the image can't load." width="100%" height="auto"/> <figcaption id="afold"> A sample of an ARC problem</figcaption> </figure> <p>ARC proved to be quiet a difficult benchmark to solve over the years. A plethora of models, many of them based on LLMs, fail to achieve human performance on ARC (i.e. 85% accuracy), despite achieving state-of-the art results across benchmarks spanning language understanding, reasoning, math, coding, among others.</p> <p>This is until the end of 2024 when OpenAI released their o3 variant of ChatGPT which surpassed human performance via test-time search.</p> <p>Is ARC solved, and thus intelligence understood? Well, not even Francois Chollet believes o3 solved intelligence or is the basis for AGI.</p> <p><strong>ARC, like all benchmarks in deep learning, tests models on problems which are previously anticipated by humans, underscoring its theory-laden nature</strong>. However, intelligence, as argued by Francois Chollet, is the ability to acquire skills to solve problems.</p> <p>The environment, or real world, is a source of infinite problems. Thus, building a more comprehensive benchmark of intelligence not only requires simulating the diversity of problems which prompts a deep learning model to acquire new skills, but also can simulate the <strong>infiniteness</strong> of problems that can drive the infinite amount of skills which can be acquired.</p> <h1 id="novelty-in-benchmarks">Novelty in benchmarks</h1> <p>Reflecting on this, we need a way to build a dynamic benchmark which can:</p> <ul> <li>incrementally become difficult to constantly drive the acquisition of new skills</li> <li>require minimal human input to automate the growing of challenging problems, and thus driving novel solutions</li> </ul> <p>Given the above desiderata, there is perhaps a way to train a bi-agentic framework consisting of this harmonious feedback loop between problem-solver and problem-generator.</p> <figure> <img src="/assets/img/feedback_loop.png" alt="Sorry. Image couldn't load." width="100%" height="auto"/> <figcaption id="cell-embedder">Illustration of the feedback loop between problem-solver and problem-generator </figcaption> </figure> <p>In this loop, we aim to convey how:</p> <ul> <li>as a starting point, a human designs some initial problems</li> <li>then, the problem-solver generates solutions to existing problems.</li> <li>the initial, simple solutions inspires more complicated problems, which is the composition of simpler problems</li> <li>the more complicated problems drives novel solutions which are the composition of simpler solutions</li> <li>so on and so forth…</li> </ul> <p>Any comments? Feedback?</p>]]></content><author><name>Xuelong An</name></author><category term="blog-post"/><category term="research"/><summary type="html"><![CDATA[my comment on benchmarks which evaluate deep learning models]]></summary></entry><entry><title type="html">Conversatoria sobre la inteligencia artificial en la medicina</title><link href="https://awxlong.github.io/blog/2025/tertulia-kennedy/" rel="alternate" type="text/html" title="Conversatoria sobre la inteligencia artificial en la medicina"/><published>2025-02-04T13:42:00+00:00</published><updated>2025-02-04T13:42:00+00:00</updated><id>https://awxlong.github.io/blog/2025/tertulia-kennedy</id><content type="html" xml:base="https://awxlong.github.io/blog/2025/tertulia-kennedy/"><![CDATA[<h1 id="el-rol-de-la-inteligencia-artificial-en-la-medicina">El Rol de la Inteligencia Artificial en la Medicina</h1> <p>Tuve la maravillosa oportunidad de dar una presentación junto con el ex-Ministro de Salud y fundador del Grupo Hospitalario Kennedy Dr. Teófilo Lama. En esta, compartí mi experiencia entorno a los usos de la inteligencia artificial (IA) en la medicina.</p> <p>El tema principal de la conversatoria trata sobre el “Pasado, Presente y Futuro de la Medicina”, en donde el Dr. Lama compartió su carrera en la medicina, cómo esta ha avanzado a través del tiempo y nos contagió con su entusiasmo e interés sobre cómo la IA poco a poco sinergiza con la medicina.</p> <figure> <img src="/assets/img/kennedy-2.jpg" alt="Sorry. Image couldn't load." width="auto" height="auto"/> <figcaption id="cell-embedder">El pasado, presente y futuro de la medicina con Dr. Lama </figcaption> </figure> <p>Durante mi turno, estructuré mi presentación en base a una conversación con un amigo quien estudia medicina:</p> <ul> <li>¿A quién asiste la IA: al paciente o al doctor?</li> <li>Costos de implementación de la IA</li> <li>Casos ejemplares</li> </ul> <h2 id="la-ia-como-un-asistente-de-diagnóstico">La IA como un asistente de diagnóstico</h2> <p>Compartí mi tesis de mi masterado en UCL, ilustrando un caso en donde la IA actúa como asistente de patólogos para el análisis a gran escala de tejido colorectal para identificar poblaciones de células en fase G0, lo cual es relevante para estudiar resistencia a quimioterapia y relapso. Compartí mi demo en: https://awxlong.github.io/assets/img/pathoinsightmil_demo.mp4</p> <p>El costo de implementar este sistema en un local médico es bastante alto. En un lado esto es debido a la alta complejidad del dato, pues las imágenes que representan la digitalización de una biopsia contiene más de 1 millón de píxeles. Por ende para entrenar estos modelos de aprendizaje profundo, así como almacenar estas imágenes, requerirían clústeres y servidores, lo cual no necesariamente estaría disponible.</p> <figure> <img src="/assets/img/kennedy-3.png" alt="Sorry. Image couldn't load." width="auto" height="auto"/> <figcaption id="cell-embedder">El presente y futuro de la medicina con la IA</figcaption> </figure> <h2 id="la-ia-como-un-asistente-para-lidiar-con-obligaciones-burocráticas">La IA como un asistente para lidiar con obligaciones burocráticas</h2> <p>Otro uso de la IA concierne implementarlo como un asistente para automatizar el llenado de formularios varios, que constituyen trabajo tedioso que todo doctor enfrenta día a día. Compartí mi proyecto sobre YachayMed https://github.com/awxlong/medical_asr. Este sistema transcribe conversaciones entre doctor y paciente con el fin de facilitar el llenado de un reporte médico de un paciente.</p> <p>En este caso, el costo de implementación sería menor debido a que el avance y accesibilidad de modelos de lenguaje es mayor que los de imágenes. En parte esto es debido a que las transcripciones tienen menor complejidad de datos (son cortas, y más o menos consisten de alrededor de 700-1000 palabras para una conversación de casi 10 minutos). Además, paralelo al movimiento de código abierto, la integración de modelos de lenguaje abre bastantes oportunidades en el ámbito médico.</p> <p>Claro, lo más accesible y fácil de implementar sería modelos estadísticos/aprendizaje mecánico como regresión lineal o logística para el análisis masivo de bases de datos como formularios de Excel. Hay problemas bastantes interesantes que pueden ser resueltos como predicción de sobrevivencia o readmisión.</p> <figure> <img src="/assets/img/kennedy-1.jpg" alt="Sorry, an unanticipated error occured and the image can't load." width="100%" height="auto"/> <figcaption id="afold"> Conversación y discusión sobre la IA en la medicina </figcaption> </figure> <p>Las diapositivas que empleé se encuentran anexado. Hay diapositivas extras explicando qué son redes neuronales y cómo han sido entrenadas.</p> <style>.pdf-embed-wrap-454047dc-ed86-42cc-a11a-67a17fa31eb5{display:flex;flex-direction:column;width:100%;height:650px}.pdf-embed-container-454047dc-ed86-42cc-a11a-67a17fa31eb5{height:100%}.pdf-link-454047dc-ed86-42cc-a11a-67a17fa31eb5{background-color:white;text-align:center;border-style:solid}.pdf-embed-container-454047dc-ed86-42cc-a11a-67a17fa31eb5 iframe{width:100%;height:100%}</style> <div class="pdf-embed-wrap-454047dc-ed86-42cc-a11a-67a17fa31eb5"> <div class="pdf-link-454047dc-ed86-42cc-a11a-67a17fa31eb5"> <a href="/assets/pdf/tertulia_ia.pdf" target="_blank">View PDF</a> </div> <div class="pdf-embed-container-454047dc-ed86-42cc-a11a-67a17fa31eb5"> <iframe src="/assets/pdf/tertulia_ia.pdf" frameborder="0" allowfullscreen=""></iframe> </div> </div>]]></content><author><name>Xuelong An</name></author><category term="blog-post"/><category term="research"/><summary type="html"><![CDATA[compartí mi experiencia sobre las aplicaciones de la IA en la medicine en el Grupo Hospitalario Kennedy, Guayaquil]]></summary></entry><entry><title type="html">The interesting analogy between language and biology</title><link href="https://awxlong.github.io/blog/2025/lang-biology/" rel="alternate" type="text/html" title="The interesting analogy between language and biology"/><published>2025-01-19T12:42:00+00:00</published><updated>2025-01-19T12:42:00+00:00</updated><id>https://awxlong.github.io/blog/2025/lang-biology</id><content type="html" xml:base="https://awxlong.github.io/blog/2025/lang-biology/"><![CDATA[<h1 id="on-the-interesting-parallels-of-language-and-biology-a-taster">On the interesting parallels of language and biology: a taster</h1> <p>There are interesting parallels between language and biology. As a result, problems surfacing in natural language processing (NLP) tasks, may well inform us about possible problems and solutions in computational biology.</p> <p>The simplest common denominator to observe the parallels concerns the analysis of sequences: algorithms and modelling paradigms like recurrent neural networks and self-attention in transformer that help process a sequence of words to solve a task like text classification can surprisingly work with sequences of genes to classify what disease does an RNA sequence correspond to. This is because at a computational level, a string of nucleotides (adenine (A), thymine (T) or uracil (U) in RNA, cytosine (C), and guanine (G)) can be <a href="https://www.sciencedirect.com/science/article/pii/S2001037021000945">represented as a sequence of letters</a>.</p> <p>Another common point concerns the representation of words and biological entities. It would not suffice to represent a word like ‘airplane’ based solely on this string (i.e. this symbol) so it is common to use a fixed-size embedding vector to denote it. This be extracted from open-source libraries like GLoVE and word2Vec. In parallel, molecules also have expert-coded or learnt <a href="https://pubs.acs.org/doi/epdf/10.1021/acs.jcim.9b00237">molecular fingerprints</a> as vector embeddings which are readily available in RDKit. Another case is that of obtaining embeddings for biological entities. A gene can be treated as a vocabulary token, while a cell can be treated <a href="https://www.biorxiv.org/content/10.1101/2023.04.30.538439v1.full.pdf">as a sentence</a>. Another work on a similar vein is <a href="https://www.biorxiv.org/content/10.1101/2023.09.11.557287v2">Cell2Sentence</a>, where gene expression (single-cell transcriptomics) is treated as text.</p> <h1 id="language-agnostic-grammar-structure-for-language-and-biology">Language-agnostic grammar: structure for language and biology</h1> <p>Inspired by Chomsky’s linguistics, there is work on learning a language-agnostic tree-like structure to learn embeddings of text, called <a href="https://arxiv.org/abs/2305.05588">Self-Structured AutoEncoder</a>. This tree-like structure combines bottom-up composition of local contextual embeddings with top-down decomposition of fully contextual embeddings to learn in an unsupervised routine. Self-StrAE achieves competitive autoencoding performance with respect to a LLM, BERT-Based variant, denoting its low parameter efficiency that reflects the parsimonious nature of grammar.</p> <p>Given the parallels with language, it is interesting to explore how would it work if Self-StrAE is applied to a DNA, or RNA sequence. What will the learnt structure tell us about the DNA sequence. Learnt embeddings would shed light into sequences of DNA which may have fucntional similarities. The compositions found by Self-StrAE would also find sequence motifs, which are short recurring patterns of DNA that map to specific biological functions like protein docking, because of frequent coocurrence leading to similar embeddings.</p> <h1 id="language-respects-constraints-so-does-biology">Language respects constraints, so does biology</h1> <p>Another interesting parallel are the constraints underlying both generation of sentences and biological entities/processes.</p> <p>Imagine that you want to generate sentences. You have a collection of sentences to train a probabilistic model on. Because we can’t control what the probabilistic model learns from the given data, how do you make sure you don’t generate an ungrammatical sentence like “jogging Octopie went”, where we have a “verb-subject-verb” structure. The simplest way would be to set up a hidden template like “subject-verb-object”<sup id="fnref:1"><a href="#fn:1" class="footnote" rel="footnote" role="doc-noteref">1</a></sup> in order to offset portion of the probabilistic model’s support<sup id="fnref:3"><a href="#fn:3" class="footnote" rel="footnote" role="doc-noteref">2</a></sup> to not put any probability mass to structures other than “subject-verb-object”. Given this, this will first guarantee that sentences follow the correct grammar rules, and second guide <a href="https://awxlong.github.io/blog/2023/sgd/">learning</a> since the model is not exploring over the whole parameter space, but only that which conform to the supplied template.</p> <p>Consider the following analogous task, given some atoms like hydrogen, carbon, oxygen, among others, you want to train a probabilistic model to predict the angle of rotation when such input atoms are assembled together into a compound. This could be relevant for a 3D reconstruction of an assembled molecule. You have a dataset of different atom-atom compounds with their associated rotation angles. If you only rely on learning, then the resulting probabilistic model may put probability mass on biologically implausible rotation angles, even if that implausible probability mass is negligible. In the end, statistics is just about counting and averaging, meaning that even if you only see that some compound like water has a bond angle of around <a href="http://witcombe.sbc.edu/water/chemistrystructure.html">105 degrees</a>, the model’s support would still put probability mass in-between 0 or 200 degrees <sup id="fnref:2"><a href="#fn:2" class="footnote" rel="footnote" role="doc-noteref">3</a></sup>. Enumerating all possible rules concerning rotation angles would be impractical, so one can resort to biomedical ontologies.</p> <p>Arguably, this is how DeepMind’s AlphaFold ensures that proteins generated from DNA input sequences are biologically plausible, as can be observed in the model’s pipeline. In it, the input sequence first goes through a database search that is subsequently converted into embeddings used to generate the protein structure. Without this first phase, this probabilistic model may output proteins that resemble the ones observed during training, at the risk of following impossible configurations.</p> <figure> <img src="/assets/img/alphafold-pipeline.png" alt="Sorry, an unanticipated error occured and the image can't load." width="100%" height="auto"/> <figcaption id="afold"> Structural constraints in the first phase concerning genetic database search and structure database search ensures that rotation angles of bonds in the compounds of the protein are biologically plausible, setting structure in learning. Figure extracted from https://www.nature.com/articles/s41586-021-03819-2 </figcaption> </figure> <p>Generating implausible proteins, or invalid angle rotations between bonds is akin to generating sentences that violate grammar rules.</p> <p>It is debatable whether the rules can be learnt from data. Rather, the role of rules and constraints might be to shape learning.</p> <figure> <img src="/assets/img/nesy-cell.png" alt="Sorry. Image couldn't load." width="100%" height="auto"/> <figcaption id="cell-embedder">A depiction of a neurosymbolic programming approach to virtual cell. Consider a single nucleotide sequence🧬 changing over time. A neural-network driven search of programs takes the sequence as input, and outputs a sequence of program or steps that transforms the input sequence to a final state. The sequence of steps serve as an explanation to the final state, which could correspond to cancer. </figcaption> </figure> <p>For further thought experiments, imagine whether a model can learn what are the rules of programming languages by only observing code, or infer the rules of grammar from just observing written text.</p> <h1 id="nlp-inspiring-future-biomedical-research-directions">NLP inspiring future biomedical research directions</h1> <p>A dictionary with mostly indisputable grammar rules are akin to biological ontologies like the Gene Ontology An interesting thought experiment hence, is can this grammar be expanded given the text available, analogous to asking whether</p> <figure> <img src="/assets/img/expand-ontology.png" alt="Sorry, an unanticipated error occured and the image can't load." width="100%" height="auto"/> <figcaption id="ontology"> . </figcaption> </figure> <h1 id="final-thoughts">Final thoughts</h1> <p>I believe that because we can natively read Human language, research on NLP is more commoditized and well-received by the public than computational genomics, despite the parallels outlined above. I think it is worth for me and anyone interested in computational biology to closely follow the research literature on language modelling to draw inspiration ofr DNA/RNA sequence modelling.</p> <p>Finally, I leave you the following thought experiment: we humans can only read human language. While we can not natively understand the language of biology, our AI-based tools can understand them.</p> <p>‘AI may just turn out to be the language to describe biology’ - Demis Hassabis’s <a href="https://www.youtube.com/watch?v=Gfr50f6ZBvo">statement</a></p> <p>If you have answers, share thoughts, you can leave a comment or please email me!</p> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:1"> <p>Sentences don’t follow this simple template, but it helps get the idea across that placing structure into the support of a probabilistic model helps guide learning. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:3"> <p>A probabilistic model’s support refers to the domain of values for which the output of the model is non-zero. <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:2"> <p>While it is true that some bonds between atoms like a carbon-carbon bond have no restricted rotation angle, others like a <a href="https://www.sciencedirect.com/science/article/pii/S0022285217302990">hydrogen peroxide</a> is constrained to a setting of rotation degrees (with some uncertainty). <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> </ol> </div>]]></content><author><name>Xuelong An</name></author><category term="blog-post"/><category term="research"/><category term="food-for-thought"/><summary type="html"><![CDATA[comments on the interesting parallels that surface in NLP and computational biology, and how each informs about problems and solutions about each other]]></summary></entry><entry><title type="html">InQuery: Text2SQL App coded with LLMs</title><link href="https://awxlong.github.io/blog/2025/inquery/" rel="alternate" type="text/html" title="InQuery: Text2SQL App coded with LLMs"/><published>2025-01-15T15:42:00+00:00</published><updated>2025-01-15T15:42:00+00:00</updated><id>https://awxlong.github.io/blog/2025/inquery</id><content type="html" xml:base="https://awxlong.github.io/blog/2025/inquery/"><![CDATA[<h1 id="why-dart">Why Dart?</h1> <p>Dart is a programming language which enables the same code to be compiled to multiple platforms, be it IOS, Android or a web platform. This means that you can build sort of “universal” applications accessible through any platform.</p> <h1 id="why-text-to-sql">Why Text to SQL?</h1> <p>Not everyone is an expert in structured language. There is a general field of research on text to SQL dedicated to users unfamiliar with this syntax navigate a database. In our project, we grounded it in the context of querying a medical database. As a sample use case, we query a <a href="https://physionet.org/content/mimic-iv-demo/1.0/">free, open-source demo of the MIMIC-IV Clinical Database</a>.</p> <h1 id="are-llms-enough-to-build-this-app">Are LLMs enough to build this app?</h1> <p>While I acknowledge the use of LLMs in building this app, their role is better described as an assistant rather than a substitute. An app is way more complicated, in the process of building it I faced a lot of problems which requires a human’s debugging skills, and continuous iterative improvements (tons of breakpoints and trying to pinpoint the source of a problem).</p> <p>For example, many of the problems which the LLM couldn’t solve:</p> <ol> <li> <p>I faced an API query error which required me to try different API connection points to identify which is the one which works and could bridge the flask backend with the front end interface.</p> </li> <li> <p>There was a problem regarding querying the database whereby I didn’t know the database should be copied in the memory of the device, otherwise I would face unknown tables identified in the database. I needed a lot of breakpoints to debug to figure this out. Originally I wanted to query an external database, but as a proof-of-concept I started easy and queried a local database. The idea should generalize quiet smoothly.</p> </li> <li> <p>There was a lot of trial and error before deciding to design the app as it is (something no LLM could anticipate at the beginning of the project).</p> </li> </ol> <p>3.1 Initially I wanted to use this BERT-based model, <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC8701710/">MedTS</a>, for my app. However, it’s difficult to use and requires intricate input preprocessing before I can use it. In my app, I’m just assumming the user will provide a natural language input, not information such as a database schema intricately parsed into a json file, conveniently preprocessed in tree structures to be fed to MedTS. MedTS is lightweight and definitely would have been good, but it’d require extensive automatization regarding preprocessing of input.</p> <p>3.2 Another approach to use a powerful text-to-SQL model is to use an open-source big model like one based on Llama, and compress it using tflite to deploy it on-device. This was not possible for me, because this powerful model is just too big to be compressed in &lt;2 gb. After many trial and error attempts, I ended up (thanks to brainstorming with Perplexity.AI) to host the LLM in a Flask-based backend and call it through an API in the app. I’ll still explore quantization to reduce the memory footprint of the sqlcoder-7b-2 used.</p> <p>The app’s name, InQuery, is meant to be a play of the words Inquiry and Query as part of SQL.</p> <p>The code along with instructions on how to run it is found at https://github.com/awxlong/ai_sql_coder. Hope you find it helpful!</p>]]></content><author><name>Xuelong An</name></author><category term="blog-post"/><category term="research"/><summary type="html"><![CDATA[a brief description of an app written in Dart with the help of Perplexity.AI, ChatGPT and DeepSeek-V3]]></summary></entry><entry><title type="html">Ideas on transitioning from monolith to manifold of models</title><link href="https://awxlong.github.io/blog/2024/manifold-vqa/" rel="alternate" type="text/html" title="Ideas on transitioning from monolith to manifold of models"/><published>2024-09-28T15:42:00+00:00</published><updated>2024-09-28T15:42:00+00:00</updated><id>https://awxlong.github.io/blog/2024/manifold-vqa</id><content type="html" xml:base="https://awxlong.github.io/blog/2024/manifold-vqa/"><![CDATA[<h1 id="from-monolith-to-manifold">From monolith to manifold</h1> <p>The common trend in deep learning is to propose a single model which can achieve SoTA performance on some well-established benchmark. However, models proposed which achieve high performance in different benchmarks carry their advantages and limitations. For example, a VQA model with a vision encoder pretrained on rare skin lesions may answer queries more accurately from patients with these edge cases, but perform badly on common lesions. Another VQA model (which could be an ablation of the former) may perform better at spotting normal skin lesions and perform badly on rare diseases. A question which arises is how can we combine their strengths and address each other’s limitations, akin to members of a team compensating for each other’s level of expertise. One approach is to combine multiple VQA models to leverage their interoperability so that they can discuss with each other as proposed in https://nips.cc/virtual/2023/76544, transitioning from a monolith model to a manifold of models. The proposed training and inference regime is very similar to the work of García and Lithgow-Serrano, (2024) found in https://aclanthology.org/2024.clinicalnlp-1.45.pdf, where the difference lies in that we propose multiple VQA model responses, instead of responses from a single VQA model, to be summarized by a powerful LLM.</p> <figure> <img src="/assets/img/training_m3g.png" alt="Sorry. Image couldn't load." width="100%" height="auto"/> <figcaption id="train">At a) we extract features from the question Q which is constructed differently per each language model, and from the stack of images I . At b) we fuse the features to be passed to the language model for free-form answer prediction. At c), each VQA model outputs an answer via greedy search (or beam search with a width of 1 ), and is trained by minimizing the cross-entropy loss function between ground-truth tokens and the predicted tokens. In the illustration we depict prompts in Spanish.</figcaption> </figure> <p>We take into account memory efficiency, and as such we implement model compression techniques for memory efficiency during fine-tuning, which includes 1) mixed-precision and 2) gradient accumulation to simulate mini-batch gradient descent. Answers are generated via greedy-search.</p> <figure> <img src="/assets/img/publication_preview/inference_m3g.png" alt="Sorry. Image couldn't load." width="100%" height="auto"/> <figcaption id="inference">Similar to training's stage a), we extract features from the question and images, and fuse them at b) so that at c) each of the language models output a list of answers. At d), the answers of each VQA model is put as context for a prompt to a LLM, where we query for a concise answer that accounts for the different diagnoses offered by each model. In the illustration we depict prompts in Spanish.</figcaption> </figure> <p>With memory efficiency concerns, the LLM is 1) quantized, 2) input tensors are loaded with 16-bit precision, 3) and a beam width of 1 (greedy search) is used for answer generation. The code is found at https://github.com/awxlong/manifold-medvqa/tree/main</p>]]></content><author><name>Xuelong An</name></author><category term="blog-post"/><category term="research"/><summary type="html"><![CDATA[my thoughts on a visual-question answering pipeline inspired by the Society of Minds]]></summary></entry><entry><title type="html">Thoughts on How to Build the Virtual Cell with Artificial Intelligence</title><link href="https://awxlong.github.io/blog/2024/thoughts-deepmind-cell/" rel="alternate" type="text/html" title="Thoughts on How to Build the Virtual Cell with Artificial Intelligence"/><published>2024-09-21T11:42:00+00:00</published><updated>2024-09-21T11:42:00+00:00</updated><id>https://awxlong.github.io/blog/2024/thoughts-deepmind-cell</id><content type="html" xml:base="https://awxlong.github.io/blog/2024/thoughts-deepmind-cell/"><![CDATA[<h1 id="thoughts-on-how-to-build-the-virtual-cell-with-artificial-intelligence-priorities-and-opportunities">Thoughts on <em>How to Build the Virtual Cell with Artificial Intelligence: Priorities and Opportunities</em></h1> <blockquote> <blockquote> <p>… [J]ust as mathematics turned out to be the right description language for physics, AI may turn out to play a similar role for biology - Demis Hassabis, CEO of DeepMind</p> </blockquote> </blockquote> <p>A very interesting position preprint on how to build a virtual cell has been published on arxiv: https://arxiv.org/abs/2409.11654. I’ve previously came across this idea of virtual cell from DeepMind CEO Demis Hassabis: https://www.youtube.com/watch?v=AuO0Y8Iwq0E. Since DeepMind built <a href="https://alphafold.com/">AlphaFold</a>, a DNA sequence 🧬 to 3D protein protein structure model, I guessed that its research team would be trying out to build the virtual cell by synthethizing a population of proteins interacting with each other. In the end, a cell is technically <em>a bag of proteins interacting with each other</em> 🦠.</p> <h1 id="first-impressions-on-the-preprint">First impressions on the preprint</h1> <p>There are many novel ideas proposed throughout the preprint. One of the main approaches proposed in this position paper is to build a foundation model (let’s call it AI Virtual Cell) which can produce embeddings at multiple scales: molecular, cellular and tissue-level universal representations. Such foundation model would be trained with multimodal data spanning genomic information (sequence data), fluorence microscopy (imaging), single-cell RNA sequencing data (sequencing data), multiplex imaging (imaging), spatial transcriptomics (spatially-resolved sequencing data, or imaging + sequencing data), among others. See the figure below</p> <figure> <img src="/assets/img/foundation-model-cell-embedder.png" alt="Sorry. Image couldn't load." width="100%" height="auto"/> <figcaption id="cell-embedder">On the left, multiple modalities of data spanning genetics, fluorescence microscopy to spatially-resolved omics, are used to train a foundatio embedder. On the right, it is depicted how an input can be transformed into a universal representation across 3 scales: molecular, cellular and tissue. Figure is cropped from the original article at https://arxiv.org/abs/2409.11654 (without the original authors' permission by the way 😅)</figcaption> </figure> <p>I understand it that such universal representations, which are essentially feature vectors $f \in \mathcal{R}$, can be used for some downstream tasks. The authors call the (neural network-based) models which use these feature vectors as “virtual instruments”, akin to digital tools🔬 to run in-silico experiments 🧫. If you have some temporal dataset that shows how genes change through mutations during metastasis, the idea is that you can use the AI Virtual Cell to obtain feature vectors of the genetic sequences, and train a network to predict the changes of genes across time.</p> <p>While I understand that the need of feature vectors is ubiquituous for any machine/deep learning task, I disagree this is enough to build a virtual cell. On one hand, there are standard caveats to representation learning and building foundation models that we must be wary of. First, we have no control on what artifacts of the dataset a deep learning model is learning, and in biology it’s extremely difficult to distinguish noise versus actual biologically meaningful perturbations. The training of such foundation model would have far-reaching, biomedical implications, and as such extra-care must be taken for training this AI Virtual Cell embedder.</p> <p>My other problem is that this position paper seems to mainly rely on statistical approaches to build this virtual cell and it’s constrained to building a model to produce representations, a form of bottom-up learning from biological raw data. It’s true that mechanistic modelling has limitations such as needing prior expertise/assumptions constrained to a simplistic setting such as modelling the growth of a population of cells assumming they want to replicate. However, I think mechanistic modelling, also known as a top-down modelling, will play a bigger role in building a virtual cell. Prof. Xavier Trepat offers a very good <a href="https://www.nature.com/articles/d41586-018-07246-8">account</a> on the complementarity of top-down and bottom-up processes to build a virtual cell. Consider the following thought experiment to note the importance of both approaches: top-down modelling allows us to explain high-level processes like traffic jams. While bottom-up processes are powerful since it allows us to thoroughly simulate and understand how a single car work, it at most help us know how a single car work, not necessarily how a population of cars lead to high-level problems. In biomedicine, if we want to further scientific discovery, mechanistic insight is indispensable for its interpretability and explanations to high-level phenomena. In that regard, deep learning and mechanistic modelling can complement each other to build a virtual cell.</p> <h1 id="neuro-symbolic-ai-for-building-next-generation-virtual-cells">Neuro-symbolic AI for building next-generation virtual cells</h1> <p>In one of the most interesting articles I’ve read recently on <a href="https://www.sciencedirect.com/science/article/pii/S0006349523002369">Building the next generation of virtual cells to understand cellular biology</a>, I think a paradigm that can merge deep learning with mechanistic modelling⚙️ is neurosymbolic AI, in particular neurosymbolic programming.</p> <p>Instead of focusing on training foundation model embedders, we can think of training a model that can output programs, where programs take as input raw biological data like a genetic sequence, and outputs a sequence of programs that can transforms the raw biological data. In the metastasis example above, the programs could explain to us how metastasis happens. See the depiction below:</p> <figure> <img src="/assets/img/nesy-cell.png" alt="Sorry. Image couldn't load." width="100%" height="auto"/> <figcaption id="cell-embedder">A depiction of a neurosymbolic programming approach to virtual cell. Consider a single nucleotide sequence🧬 changing over time. A neural-network driven search of programs takes the sequence as input, and outputs a sequence of program or steps that transforms the input sequence to a final state. The sequence of steps serve as an explanation to the final state, which could correspond to cancer. </figcaption> </figure> <h1 id="inverse-reinforcement-to-model-cell-behavior">Inverse reinforcement to model cell behavior</h1> <p>Another approach to building a virtual cell which I find very interesting and promising is by integrating inverse reinforcement learning (RL) as argued in this article: https://www.frontiersin.org/journals/systems-biology/articles/10.3389/fsysb.2024.1333760/full. One caveat in mechanistic modelling is its strong assumptions, for example, “cancer cells metastasize because they want to replicate”. This is <em>disputable</em>, what if the goal of cancer cells was different, and more nuanced than intially assummed. Inverse RL can alleviate this modelling assumption by not specifying some reward for a particular goal, but derive the reward function from observe behavior from cancer cells. The above paper proposes the following diagram, in which the first step on transforming the microscopy image to a cell state can make use of the above AI Virtual Cell embedder.</p> <figure> <img src="/assets/img/irl.png" alt="Sorry. Image couldn't load." width="100%" height="auto"/> <figcaption id="cell-embedder">A diagram of how to use inverse reinforcement learning to model cell behavior in a dynamic feedback loop with wet-lab experiments to validate model predictions. </figcaption> </figure> <p>There are many approaches to building a virtual cell, and I think a combination of the above methods: deep learning, neurosymbolic AI and reinforcement learning, among others, will be needed together to build a virtual cell 🦠. How exciting times we’re living⚛. <strong>What do you think of the virtual cell?</strong></p> <h3 id="a-brief-thought-on-serendipity-">A brief thought on serendipity 🧠🪐</h3> <p>Many methods in AI like neurosymbolic AI or reinforcement learning are not originally designed to solve biomedical tasks like single-cell data analysis, in a way such as a sequence alignment algorithm is tailored for identifying similarities in gene sequences or a deep network architecture is assembled to solve a medical imaging reconstruction task. At its core, research in AI is to understand how the brain works. Despite pursuing how human intelligence functions, this can nonetheless can yield unexpected insights into tackling problems in completely unrelated fields like network biology or cell science.</p> <p>The above statement is supported by anecdotal evidence where scientific research translated into overarching technological applications for social good on completely unrelated fields. My confidence on such an idea can come from Prof. Geoffrey Hinton’s <a href="https://www.youtube.com/watch?v=qpoRO378qRY">interview with CBS</a>, among the endeavors of other researchers pursuing science whose work was converted into technologies benefiting humankind. Efforts include:</p> <ul> <li><a href="https://arstechnica.com/health/2023/10/after-being-demoted-and-forced-to-retire-mrna-researcher-wins-nobel/">Prof. Katalin Karikó</a>, whose pursuit in understanding the central dogma of biology, namely how messenger-RNA translates into proteins, laid the foundation for the design of mRNA vaccines against the coronavirus during the COVID-19 pandemic.</li> <li>Prof. Yann LeCun, Prof. Yoshua Bengio, Prof. Jürgen Schmidhuber and Prof. Geoffrey Hinton himself, whose research into how the human brain works, such as how to simulate the visual cortex, how to reproduce human language, how can a machine achieve self-reference or how machines can learn like human beings, kickstarted the Third Revolution of Artificial Intelligence that can translate into a plethora of applications spanning over biomedicine</li> <li>Prof. Noam Chomsky’s work on a universal grammar underlying Human thought for understanding human language, which helped inspire work like the design of the <a href="https://en.wikipedia.org/wiki/Noam_Chomsky#Reception_and_influence">FORTRAN programming language</a></li> <li>And many more examples, where who knows how research on intelligence can help with simulating a biological cell.</li> </ul> <p>If the above anecdotes remind you of the book <a href="https://link.springer.com/book/10.1007/978-3-319-15524-1">Why Greatness Cannot Be Planned</a> by Prof. Kenneth O. Stanley and Joel Lehman, then there is another perspective from which to support the idea that basic science can fuel technological progress. We don’t know what are the stepping stones for achieving technological progress. Therefore, to achieve progress, we may have to be creative in the questions we ask and formulate novel ideas hoping and rely to some extent serendipity, that some of them will translate into groundbreaking innovations.</p> ]]></content><author><name>Xuelong An</name></author><category term="blog-post"/><category term="research"/><summary type="html"><![CDATA[my comments various papers on how to build a virtual cell]]></summary></entry></feed>