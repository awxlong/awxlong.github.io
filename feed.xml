<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://awxlong.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://awxlong.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-12-02T17:15:40+00:00</updated><id>https://awxlong.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Ideas on transitioning from monolith to manifold of models</title><link href="https://awxlong.github.io/blog/2024/manifold-vqa/" rel="alternate" type="text/html" title="Ideas on transitioning from monolith to manifold of models"/><published>2024-09-28T15:42:00+00:00</published><updated>2024-09-28T15:42:00+00:00</updated><id>https://awxlong.github.io/blog/2024/manifold-vqa</id><content type="html" xml:base="https://awxlong.github.io/blog/2024/manifold-vqa/"><![CDATA[<h1 id="from-monolith-to-manifold">From monolith to manifold</h1> <p>The common trend in deep learning is to propose a single model which can achieve SoTA performance on some well-established benchmark. However, models proposed which achieve high performance in different benchmarks carry their advantages and limitations. For example, a VQA model with a vision encoder pretrained on rare skin lesions may answer queries more accurately from patients with these edge cases, but perform badly on common lesions. Another VQA model (which could be an ablation of the former) may perform better at spotting normal skin lesions and perform badly on rare diseases. A question which arises is how can we combine their strengths and address each other‚Äôs limitations, akin to members of a team compensating for each other‚Äôs level of expertise. One approach is to combine multiple VQA models to leverage their interoperability so that they can discuss with each other as proposed in https://nips.cc/virtual/2023/76544, transitioning from a monolith model to a manifold of models. The proposed training and inference regime is very similar to the work of Garc√≠a and Lithgow-Serrano, (2024) found in https://aclanthology.org/2024.clinicalnlp-1.45.pdf, where the difference lies in that we propose multiple VQA model responses, instead of responses from a single VQA model, to be summarized by a powerful LLM.</p> <figure> <img src="/assets/img/training_m3g.png" alt="Sorry. Image couldn't load." width="100%" height="auto"/> <figcaption id="train">At a) we extract features from the question Q which is constructed differently per each language model, and from the stack of images I . At b) we fuse the features to be passed to the language model for free-form answer prediction. At c), each VQA model outputs an answer via greedy search (or beam search with a width of 1 ), and is trained by minimizing the cross-entropy loss function between ground-truth tokens and the predicted tokens. In the illustration we depict prompts in Spanish.</figcaption> </figure> <p>We take into account memory efficiency, and as such we implement model compression techniques for memory efficiency during fine-tuning, which includes 1) mixed-precision and 2) gradient accumulation to simulate mini-batch gradient descent. Answers are generated via greedy-search.</p> <figure> <img src="/assets/img/publication_preview/inference_m3g.png" alt="Sorry. Image couldn't load." width="100%" height="auto"/> <figcaption id="inference">Similar to training's stage a), we extract features from the question and images, and fuse them at b) so that at c) each of the language models output a list of answers. At d), the answers of each VQA model is put as context for a prompt to a LLM, where we query for a concise answer that accounts for the different diagnoses offered by each model. In the illustration we depict prompts in Spanish.</figcaption> </figure> <p>With memory efficiency concerns, the LLM is 1) quantized, 2) input tensors are loaded with 16-bit precision, 3) and a beam width of 1 (greedy search) is used for answer generation. The code is found at https://github.com/awxlong/manifold-medvqa/tree/main</p>]]></content><author><name>Xuelong An</name></author><category term="blog-post"/><category term="research"/><summary type="html"><![CDATA[my thoughts on a visual-question answering pipeline inspired by the Society of Minds]]></summary></entry><entry><title type="html">Thoughts on How to Build the Virtual Cell with Artificial Intelligence</title><link href="https://awxlong.github.io/blog/2024/thoughts-deepmind-cell/" rel="alternate" type="text/html" title="Thoughts on How to Build the Virtual Cell with Artificial Intelligence"/><published>2024-09-21T11:42:00+00:00</published><updated>2024-09-21T11:42:00+00:00</updated><id>https://awxlong.github.io/blog/2024/thoughts-deepmind-cell</id><content type="html" xml:base="https://awxlong.github.io/blog/2024/thoughts-deepmind-cell/"><![CDATA[<h1 id="thoughts-on-how-to-build-the-virtual-cell-with-artificial-intelligence-priorities-and-opportunities">Thoughts on <em>How to Build the Virtual Cell with Artificial Intelligence: Priorities and Opportunities</em></h1> <blockquote> <blockquote> <p>‚Ä¶ [J]ust as mathematics turned out to be the right description language for physics, AI may turn out to play a similar role for biology - Demis Hassabis, CEO of DeepMind</p> </blockquote> </blockquote> <p>A very interesting position preprint on how to build a virtual cell has been published on arxiv: https://arxiv.org/abs/2409.11654. I‚Äôve previously came across this idea of virtual cell from DeepMind CEO Demis Hassabis: https://www.youtube.com/watch?v=AuO0Y8Iwq0E. Since DeepMind built <a href="https://alphafold.com/">AlphaFold</a>, a DNA sequence üß¨ to 3D protein protein structure model, I guessed that its research team would be trying out to build the virtual cell by synthethizing a population of proteins interacting with each other. In the end, a cell is technically <em>a bag of proteins interacting with each other</em> ü¶†.</p> <h1 id="first-impressions-on-the-preprint">First impressions on the preprint</h1> <p>There are many novel ideas proposed throughout the preprint. One of the main approaches proposed in this position paper is to build a foundation model (let‚Äôs call it AI Virtual Cell) which can produce embeddings at multiple scales: molecular, cellular and tissue-level universal representations. Such foundation model would be trained with multimodal data spanning genomic information (sequence data), fluorence microscopy (imaging), single-cell RNA sequencing data (sequencing data), multiplex imaging (imaging), spatial transcriptomics (spatially-resolved sequencing data, or imaging + sequencing data), among others. See the figure below</p> <figure> <img src="/assets/img/foundation-model-cell-embedder.png" alt="Sorry. Image couldn't load." width="100%" height="auto"/> <figcaption id="cell-embedder">On the left, multiple modalities of data spanning genetics, fluorescence microscopy to spatially-resolved omics, are used to train a foundatio embedder. On the right, it is depicted how an input can be transformed into a universal representation across 3 scales: molecular, cellular and tissue. Figure is cropped from the original article at https://arxiv.org/abs/2409.11654 (without the original authors' permission by the way üòÖ)</figcaption> </figure> <p>I understand it that such universal representations, which are essentially feature vectors $f \in \mathcal{R}$, can be used for some downstream tasks. The authors call the (neural network-based) models which use these feature vectors as ‚Äúvirtual instruments‚Äù, akin to digital toolsüî¨ to run in-silico experiments üß´. If you have some temporal dataset that shows how genes change through mutations during metastasis, the idea is that you can use the AI Virtual Cell to obtain feature vectors of the genetic sequences, and train a network to predict the changes of genes across time.</p> <p>While I understand that the need of feature vectors is ubiquituous for any machine/deep learning task, I disagree this is enough to build a virtual cell. On one hand, there are standard caveats to representation learning and building foundation models that we must be wary of. First, we have no control on what artifacts of the dataset a deep learning model is learning, and in biology it‚Äôs extremely difficult to distinguish noise versus actual biologically meaningful perturbations. The training of such foundation model would have far-reaching, biomedical implications, and as such extra-care must be taken for training this AI Virtual Cell embedder.</p> <p>My other problem is that this position paper seems to mainly rely on statistical approaches to build this virtual cell and it‚Äôs constrained to building a model to produce representations, a form of bottom-up learning from biological raw data. It‚Äôs true that mechanistic modelling has limitations such as needing prior expertise/assumptions constrained to a simplistic setting such as modelling the growth of a population of cells assumming they want to replicate. However, I think mechanistic modelling, also known as a top-down modelling, will play a bigger role in building a virtual cell. Prof. Xavier Trepat offers a very good <a href="https://www.nature.com/articles/d41586-018-07246-8">account</a> on the complementarity of top-down and bottom-up processes to build a virtual cell. Consider the following thought experiment to note the importance of both approaches: top-down modelling allows us to explain high-level processes like traffic jams. While bottom-up processes are powerful since it allows us to thoroughly simulate and understand how a single car work, it at most help us know how a single car work, not necessarily how a population of cars lead to high-level problems. In biomedicine, if we want to further scientific discovery, mechanistic insight is indispensable for its interpretability and explanations to high-level phenomena. In that regard, deep learning and mechanistic modelling can complement each other to build a virtual cell.</p> <h1 id="neuro-symbolic-ai-for-building-next-generation-virtual-cells">Neuro-symbolic AI for building next-generation virtual cells</h1> <p>In one of the most interesting articles I‚Äôve read recently on <a href="https://www.sciencedirect.com/science/article/pii/S0006349523002369">Building the next generation of virtual cells to understand cellular biology</a>, I think a paradigm that can merge deep learning with mechanistic modelling‚öôÔ∏è is neurosymbolic AI, in particular neurosymbolic programming.</p> <p>Instead of focusing on training foundation model embedders, we can think of training a model that can output programs, where programs take as input raw biological data like a genetic sequence, and outputs a sequence of programs that can transforms the raw biological data. In the metastasis example above, the programs could explain to us how metastasis happens. See the depiction below:</p> <figure> <img src="/assets/img/nesy-cell.png" alt="Sorry. Image couldn't load." width="100%" height="auto"/> <figcaption id="cell-embedder">A depiction of a neurosymbolic programming approach to virtual cell. Consider a single nucleotide sequenceüß¨ changing over time. A neural-network driven search of programs takes the sequence as input, and outputs a sequence of program or steps that transforms the input sequence to a final state. The sequence of steps serve as an explanation to the final state, which could correspond to cancer. </figcaption> </figure> <h1 id="inverse-reinforcement-to-model-cell-behavior">Inverse reinforcement to model cell behavior</h1> <p>Another approach to building a virtual cell which I find very interesting and promising is by integrating inverse reinforcement learning (RL) as argued in this article: https://www.frontiersin.org/journals/systems-biology/articles/10.3389/fsysb.2024.1333760/full. One caveat in mechanistic modelling is its strong assumptions, for example, ‚Äúcancer cells metastasize because they want to replicate‚Äù. This is <em>disputable</em>, what if the goal of cancer cells was different, and more nuanced than intially assummed. Inverse RL can alleviate this modelling assumption by not specifying some reward for a particular goal, but derive the reward function from observe behavior from cancer cells. The above paper proposes the following diagram, in which the first step on transforming the microscopy image to a cell state can make use of the above AI Virtual Cell embedder.</p> <figure> <img src="/assets/img/irl.png" alt="Sorry. Image couldn't load." width="100%" height="auto"/> <figcaption id="cell-embedder">A diagram of how to use inverse reinforcement learning to model cell behavior in a dynamic feedback loop with wet-lab experiments to validate model predictions. </figcaption> </figure> <p>There are many approaches to building a virtual cell, and I think a combination of the above methods: deep learning, neurosymbolic AI and reinforcement learning, among others, will be needed together to build a virtual cell ü¶†. How exciting times we‚Äôre living‚öõ. <strong>What do you think of the virtual cell?</strong></p> <h3 id="a-brief-thought-on-serendipity-">A brief thought on serendipity üß†ü™ê</h3> <p>Many methods in AI like neurosymbolic AI or reinforcement learning are not originally designed to solve biomedical tasks like single-cell data analysis, in a way such as a sequence alignment algorithm is tailored for identifying similarities in gene sequences or a deep network architecture is assembled to solve a medical imaging reconstruction task. At its core, research in AI is to understand how the brain works. Despite pursuing how human intelligence functions, this can nonetheless can yield unexpected insights into tackling problems in completely unrelated fields like network biology or cell science.</p> <p>The above statement is supported by anecdotal evidence where scientific research translated into overarching technological applications for social good on completely unrelated fields. My confidence on such an idea can come from Prof. Geoffrey Hinton‚Äôs <a href="https://www.youtube.com/watch?v=qpoRO378qRY">interview with CBS</a>, among the endeavors of other researchers pursuing science whose work was converted into technologies benefiting humankind. Efforts include:</p> <ul> <li><a href="https://arstechnica.com/health/2023/10/after-being-demoted-and-forced-to-retire-mrna-researcher-wins-nobel/">Prof. Katalin Karik√≥</a>, whose pursuit in understanding the central dogma of biology, namely how messenger-RNA translates into proteins, laid the foundation for the design of mRNA vaccines against the coronavirus during the COVID-19 pandemic.</li> <li>Prof. Yann LeCun, Prof. Yoshua Bengio, Prof. J√ºrgen Schmidhuber and Prof. Geoffrey Hinton himself, whose research into how the human brain works, such as how to simulate the visual cortex, how to reproduce human language, how can a machine achieve self-reference or how machines can learn like human beings, kickstarted the Third Revolution of Artificial Intelligence that can translate into a plethora of applications spanning over biomedicine</li> <li>Prof. Noam Chomsky‚Äôs work on a universal grammar underlying Human thought for understanding human language, which helped inspire work like the design of the <a href="https://en.wikipedia.org/wiki/Noam_Chomsky#Reception_and_influence">FORTRAN programming language</a></li> <li>And many more examples, where who knows how research on intelligence can help with simulating a biological cell.</li> </ul> <p>If the above anecdotes remind you of the book <a href="https://link.springer.com/book/10.1007/978-3-319-15524-1">Why Greatness Cannot Be Planned</a> by Prof. Kenneth O. Stanley and Joel Lehman, then there is another perspective from which to support the idea that basic science can fuel technological progress. We don‚Äôt know what are the stepping stones for achieving technological progress. Therefore, to achieve progress, we may have to be creative in the questions we ask and formulate novel ideas hoping and rely to some extent serendipity, that some of them will translate into groundbreaking innovations.</p> ]]></content><author><name>Xuelong An</name></author><category term="blog-post"/><category term="research"/><summary type="html"><![CDATA[my comments various papers on how to build a virtual cell]]></summary></entry><entry><title type="html">phenotype = (genotype + environment) * consciousness. Reflections on The consilience of knowledge by Edward O. Wilson</title><link href="https://awxlong.github.io/blog/2024/consilience/" rel="alternate" type="text/html" title="phenotype = (genotype + environment) * consciousness. Reflections on The consilience of knowledge by Edward O. Wilson"/><published>2024-06-22T08:42:00+00:00</published><updated>2024-06-22T08:42:00+00:00</updated><id>https://awxlong.github.io/blog/2024/consilience</id><content type="html" xml:base="https://awxlong.github.io/blog/2024/consilience/"><![CDATA[<h1 id="why-consilience"><strong>Why Consilience?</strong></h1> <p>The <strong>consilience</strong> of knowledge essentially means finding the principles which underlying two or more distinct branches of knowledge. People who subscribe to the idea that knowledge, in its many shapes and forms, is intimately connected, can be referred to as ‚Äúconsilientists‚Äù. We are often in awe by questions such as ‚Äúwhat‚Äôs the fundamental question?‚Äù to ask in particularly field of knowledge such as math, or artificial intelligence. The unknowns behind such fundamental questions, along with their answers, would shed insight into how seemingly disparate fields like AI and, say, cuisine, are deep down interconnected. The intrisic value of asking fundamental questions, and gauging principles of knowledge rather than superficial forms of knowledge, is that while consilientists can‚Äôt know everything, they can <em>know the things that help them understand most things</em>.</p> <p>Consilientists are lateral thinkers, meaning that they like to focus on the ‚Äúbig picture‚Äù, as in how a piece of knowledge fits with other knowledge, instead of compromising oneself to understanding thoroughly this piece of knowledge. To achieve consilience, it is required to know something about everything, and find a common principle that could explain most things. It is not being a polymath, i.e., knowing everything. It is being open to several ideas, and that ideas that seemingly contradict each other, may actually complement once we think deeply enough about them. For example, the empiricist vs. nativist debate in cognitive science (https://plato.stanford.edu/entries/innateness-cognition/) . To me, while empiricism and nativism are advertised as opposing ideas, in the eyes of a consilient researcher, they‚Äôre complementary. This is because the bottom-up epistemological approach of empiricists is intricately tied to the top-down perception of the world advocated by nativists, as depicted below.</p> <figure> <img src="/assets/img/induction_deduction.png" alt="Sorry. Image couldn't load." width="100%" height="auto"/> <figcaption id="bottleneck">A depiction of inter-relation between induction and deduction. One can't process data without an a-priori model (theory-landeness). The model is data-dependent, and is part of an active loop of information exchange. </figcaption> </figure> <p>Another seemingly dichotomy is that of questions and answers. Problems are, in essence, solutions. This is because we can only ask questions for which we can have the answer, or we ask the questions based on the answer we can obtain. Consilientists questions can be of the form:</p> <ul> <li> <p>Are two seemingly different ideas just two faces of the same coin?</p> </li> <li> <p>Are two ideas that are often pitted against each other complementary to each other, rather than contradictory?</p> </li> </ul> <p>There are different ways to achieve consilience, i.e., to search for an universal principle, or a theory of everything.</p> <p>Prof. Edward O. Wilson mainly advocates for common principles through an empiricist/reductionist, excluding approaches such as rationalism or deduction. In the literature, empiricists and rationalists are commonly pitted against each other, on the assumption that acceptance of empiricism negates rationalism. But as argued in point 2 above, to my opinion, they not only are not against each other, they complement each other. Empiricist can explain how our mind can learn from external data, but can‚Äôt explain how we reason about math, simply because math doesn‚Äôt exist in the real world. Nativists can answer how we reason about math by arguing it is endowed by our genes after some random mutation in that marked the beginning of the Homo sapiens species, but this doesn‚Äôt mean that they can reject the relevance of learning from environmental cues. I‚Äôm personally critical of reductionism or empiricism (for a better take please read David Deutsch‚Äôs The Beginning of Infinity). The problem with reductionism is its lack of explanatory power for meaningful phenomena like universal cultural values, history of the emergence of nation-states, or love. At its core, reductionism aims at proposing as a theory of everything the interplay of molecules and fundamental forces, which equifinal outcome make them meaningless to explain any phenomena. The problem with empiricism is that one often shapes hypothesis and instruments of measurement based on the evidence one wants to collect.</p> <p>In the book by Edward Wilson, he discussed the fundaments which tie the biological and the social sciences, of which can be succintly summarized as:</p> \[phenotype = genotype + environment\] <ul> <li>phenotype encapsulates the physical, behavioral and emotional trait of an individual organism.</li> <li>gene refers to the selfish gene, or mutations, that are inherited from progenitors. Genetics is also what predisposes us to fight against each other, and our consciousness can either amplify this predisposition for war or tone it down.</li> <li>environment refers to the geographical constraints in which an organism lives and influences how a gene expresses, and thus how an organism develops. Epigenetic rules or epigenesis is heredity and environmental factors</li> </ul> <p>The beauty of such equation rests in the infinite amount of knowledge which hides behind such abstract simplicity. Phenotype is regarded as an abstract term with which we describe the human or humans‚Äô conditions, the subject of study of the social sciences.</p> <p>I have some criticism of this equation, in that it doesn‚Äôt account for the uniqueness of human beings. The equation is ‚Äòuniversal‚Äô to all living beings, such as animals. One phenotypic trait is intelligence, with which from the equation we can argue that it is intimately endowed by the genes and environment. However, I don‚Äôt believe that animals have the same competence as us humans, and instead propose the following equation, which just slightly modifies the equation above:</p> <h1 id="phenotype--genotype--environment--consciousness"><strong>\(phenotype = (genotype + environment) * consciousness\)</strong></h1> <p>Marvelous! Consciousness, which itself is something which we don‚Äôt understand nor define, can explain the uniqueness of us human beings: we have more ‚Äúconsciousness‚Äù than non-human animals. The consciousness in this equation is an umbrella term to encapsulate many other terms: creativity, hypothesis making, mathematical wisdom, emotions, qualia, among others.</p> <p>I personally add consciousness as an additional component to epigenetic rules which influences our phenotype. I placed it in the right hand side of the equation, instead of the left hand side, on the assumption that it is not a physical property. This is debatable nonetheless. Consciousness refers to our mental capacity (call it intelligence if you want) which can shake off the shackles of our genes and environment. Consciousness, or the capacity to stay conscious, is the central drive of humans to domesticate other species, nature itself and, through science and technology, pursue a meaningful life beyond what the selfish gene and environment dictate. Unlike animals, with a lower degree of consciousness (or hunekers as Douglas Hofstadter would call), then non-human animals are only able to act according to their epigenetic rules. Consciousness allowed us humans to alter drastically our environment, to the point of compromising our long-term survival. Soon, it would also allow us to modify our very that predisposes to a large extent our phenotype.</p> <p>The equation essentially states the human condition (the phenotype) is the result of the human‚Äôs genome, environment in which he developed, everything moderated by consciousness. You may have seen the equation $phenotype = genotype + environment$. By adding the $\times consciousness$ portion, we illustrate the difference between us and the non-human animals. Namely, the condition of non-human animals, which may have a low-degree of consciousness, are mostly determined by their genes and environment. We, however, can <em>influence both our genes and environment</em> thanks to our consciousness another thought experiment is that the consciousness variable could be universal, as in, consciousness is the same ‚Äúprinciple‚Äù for all humans, but it is personalized because of each human‚Äôs unique gene and environment.</p> <p>Another interesting thought experiment derived from the equation is that the consciousness variable is perhaps universal, rather than localized to each individual. This entails the existence of a ‚Äúcollective consciousness‚Äù, and each individual is a personalization of such collective consciosness dependent on the particular characteristics of our randomly delegated genes and allocated environment.</p> <h2 id="some-comments-on-the-comparisons-between-humans-and-non-humans">Some comments on the comparisons between humans and non-humans</h2> <p>Another thread of thought spun from the equation delineates the human condition with the non-human condition. Namely, we are <em>fundamentally</em> distinct to non-human animals, despite several human beings stating otherwise. We argue that animals don‚Äôt display intelligent behavior in the sense of intelligence meant by ‚Äòhuman intelligence‚Äô.</p> <p>Perhaps we perceive intelligence in non-human animals because a particular trait of our consciousness (these mysterious mental machinations) is to story-tell, leading us to perceive higher intelligence in other non-human animals when there isn‚Äôt, because non-human animals are, in that regards, slave to their genes and environment.</p> <p>A dolphin or dog that can seemingly count, a bonobo that can solve puzzles, a herd of elephants that supposedly organize a funeral or squid that can squirt to anger human spectators is perhaps not evidence of cognition or consciousness in non-human animals, at least at the same degree of their human counterparts, but rather behavior that‚Äôs pre encoded in their genes. What is impressive, in my opinion, is our brains‚Äô capability to craft stories, stories which are causal interpretations of these natural events:</p> <div class="embed-container"> <iframe width="560" height="315" src="https://www.youtube.com/embed/" frameborder="0" allowfullscreen=""></iframe> </div> <p>dolphin ‚Äòcounting‚Äô</p> <div class="embed-container"> <iframe width="560" height="315" src="https://www.youtube.com/embed/" frameborder="0" allowfullscreen=""></iframe> </div> <p>octopus ‚Äòopening jar‚Äô</p> <div class="embed-container"> <iframe width="560" height="315" src="https://www.youtube.com/embed/" frameborder="0" allowfullscreen=""></iframe> </div> <p>elephants ‚Äòmourning‚Äô</p>]]></content><author><name></name></author><category term="blog-post"/><summary type="html"><![CDATA[my afterthoughts on The consilience of knowledge, a book by Edward O. Wilson]]></summary></entry><entry><title type="html">Reflections on the Hacking the Human Vasculature Kaggle Competition</title><link href="https://awxlong.github.io/blog/2024/hack-vasculature/" rel="alternate" type="text/html" title="Reflections on the Hacking the Human Vasculature Kaggle Competition"/><published>2024-03-09T08:42:00+00:00</published><updated>2024-03-09T08:42:00+00:00</updated><id>https://awxlong.github.io/blog/2024/hack-vasculature</id><content type="html" xml:base="https://awxlong.github.io/blog/2024/hack-vasculature/"><![CDATA[<p>George Tang and I participated in the SenNet + HOA Hacking the Human Vasculature <a href="https://www.kaggle.com/competitions/blood-vessel-segmentation">Kaggle Competition</a>. We didn‚Äôt manage to submit good results prior to the competition deadline üòÖ. However, after the competition deadline, we managed to obtain a competitive segmentation DICE score that could have earned us ~10th place in the competition.</p> <h1 id="training-the-model">Training the model</h1> <ul> <li>My training notebook is at: https://www.kaggle.com/code/awxlong/hack-vasculature-transfer-learning <ul> <li>It consists of adapting the nnUnet proposed in https://github.com/MIC-DKFZ/nnUNet loaded with pretrained weights on hepatic vessel segmentation downloaded from https://zenodo.org/records/3734294/files/Task008_HepaticVessel.zip?download=1</li> <li>Finetuning the nnUnet architecture to the provided dataset in the competition for 15 epochs</li> </ul> </li> <li>My inference notebook is at: https://www.kaggle.com/code/awxlong/hack-vasculature-transfer-learning-inference <ul> <li>It consists of loading the weights trained above and inferring over the test dataset.</li> <li>We adopt <a href="https://www.kaggle.com/competitions/blood-vessel-segmentation/discussion/475074">post-processing steps</a> by 3rd place winner (shout-out to ForcewithMe) which consists of tuning a threshold for binarizing the segmentation mask which helped us boost the performance of our model up to a competitive 0.67 Dice score. For reasons unknown, without their post-processing step, my segmentation DICE score was stuck at ~0.001.</li> </ul> </li> </ul> <h1 id="reflection">Reflection</h1> <ul> <li>Prior to transfer learning, I‚Äôve attempted finetuning the foundational model MedSAM adapted from https://github.com/bowang-lab/MedSAM. My validation DICE score was stuck at ~0.18, and I argue this is because foundational models are harder to fine-tune as well as the this task was ‚Äúsyntactically‚Äù different to what the foundational model was previously trained on. Blood vessels are thinner, and resulting segmentation masks are more sparse compared to the datasets that MedSAM was trained on, which were most likely images of larger organs. ‚ÄòSemantically‚Äô however, MedSAM would have been very appropiate for this task because technically it had ‚Äòmedical‚Äô knowledge on what organs are.</li> <li>My personal advice is that if you opt for transfer learning, focus on the ‚Äòsyntax‚Äô of the task some model was trained on. In my case, I chose nnUnet‚Äôs hepatic blood vessel segmentation because I noticed the masks it was previously trained on are ‚Äòsparse‚Äô and ‚Äòthin‚Äô. I wouldn‚Äôt prefer, for instance, some segmentation model pretrained on ‚Äòocular blood vessels‚Äô because even though they are ‚Äòsemantically‚Äô the same task, syntactically, their segmentation masks are thin, but they weren‚Äôt sparse.</li> </ul> <h1 id="presentation">Presentation</h1> <p>I did a presentation for the Nexus Lab Sympossium on March 9th, with slides here attached below:</p> <style>.pdf-embed-wrap-51791fde-ffa1-41f3-ab27-b080da272253{display:flex;flex-direction:column;width:100%;height:650px}.pdf-embed-container-51791fde-ffa1-41f3-ab27-b080da272253{height:100%}.pdf-link-51791fde-ffa1-41f3-ab27-b080da272253{background-color:white;text-align:center;border-style:solid}.pdf-embed-container-51791fde-ffa1-41f3-ab27-b080da272253 iframe{width:100%;height:100%}</style> <div class="pdf-embed-wrap-51791fde-ffa1-41f3-ab27-b080da272253"> <div class="pdf-link-51791fde-ffa1-41f3-ab27-b080da272253"> <a href="/assets/pdf/hacking-the-human-vasculature.pdf" target="_blank">View PDF</a> </div> <div class="pdf-embed-container-51791fde-ffa1-41f3-ab27-b080da272253"> <iframe src="/assets/pdf/hacking-the-human-vasculature.pdf" frameborder="0" allowfullscreen=""></iframe> </div> </div>]]></content><author><name></name></author><category term="blog-post"/><summary type="html"><![CDATA[transfer learning from nnUnet's hepatic vessel segmentation to renal vessel segmentation]]></summary></entry><entry><title type="html">A probabilistic circuit for imputing missing tabular data</title><link href="https://awxlong.github.io/blog/2023/pc-imputation/" rel="alternate" type="text/html" title="A probabilistic circuit for imputing missing tabular data"/><published>2023-12-22T08:42:00+00:00</published><updated>2023-12-22T08:42:00+00:00</updated><id>https://awxlong.github.io/blog/2023/pc-imputation</id><content type="html" xml:base="https://awxlong.github.io/blog/2023/pc-imputation/"><![CDATA[<h1 id="spns-for-imputing-data">SPNs for imputing data</h1> <p>The following is a Jupyter notebook ran on Google Colab using Kaggle‚Äôs Titanic dataset to illustrate a practical use case of a probabilistic circuit, a sum-product network, from <a href="https://github.com/deeprob-org/deeprob-kit">deepprob-kit</a>: to impute missing tabular data.</p> <p>This notebook is forked from a Kaggle <a href="https://www.kaggle.com/code/ttminh27/using-autoencoder-to-impute-missing-data">tutorial</a> on using a Tensorflow‚Äôs autoencoder to impute missing data. Standard autoencoders can‚Äôt:</p> <ul> <li>custom fill-in missing data</li> <li>flexibly incorporate domain knowledge like what distribution is best used to model a feature</li> <li>Furthermore, p;robabilistic circuits can tractably compute missing data through maximum a posteriori estimation.</li> </ul> <div class="jupyter-notebook" style="position: relative; width: 100%; margin: 0 auto;"> <div class="jupyter-notebook-iframe-container"> <iframe src="/assets/jupyter/using_pc_to_impute_missing_data.ipynb.html" style="position: absolute; top: 0; left: 0; border-style: none;" width="100%" height="100%" onload="this.parentElement.style.paddingBottom = (this.contentWindow.document.documentElement.scrollHeight + 10) + 'px'"></iframe> </div> </div>]]></content><author><name></name></author><category term="blog-post"/><category term="class-notes"/><category term="food-for-thought"/><summary type="html"><![CDATA[using a sum-product network to flexibly impute missing data in Kaggle's Titanic dataset]]></summary></entry><entry><title type="html">On the Turing Test and Large Language Models</title><link href="https://awxlong.github.io/blog/2023/turing-test/" rel="alternate" type="text/html" title="On the Turing Test and Large Language Models"/><published>2023-12-09T09:42:00+00:00</published><updated>2023-12-09T09:42:00+00:00</updated><id>https://awxlong.github.io/blog/2023/turing-test</id><content type="html" xml:base="https://awxlong.github.io/blog/2023/turing-test/"><![CDATA[<h1 id="on-benchmarks-of-human-intelligence">On benchmarks of Human intelligence</h1> <p>There is a plethora of claims surrounding the emergence of actual or surpasssing Human intelligence by Large Language Models. One, by one, these contextualized autocomplete models are given the labels of having <a href="https://arxiv.org/abs/2305.03731v2">working memory</a>, <a href="https://analyticsindiamag.com/text-is-a-projection-of-the-world-says-openais-sutskever/">compresses</a> a <a href="https://www.linkedin.com/posts/armand-ruiz_llms-do-more-than-predict-the-next-word-activity-7134512576318623744-7BlG?utm_source=share&amp;utm_medium=member_desktop">‚Äúworld model‚Äù</a>, or it signals <a href="https://arxiv.org/abs/2303.12712">sparks of Artificial General Intelligence</a>.</p> <p>There are a list of benchmarks backing up their claims. These benchmarks come with questions-answers pairs, where high performance signifies that a model is able to simulate a faculty of Human intelligence like language.</p> <p>However, most if not all benchmarks are tailored for what LLMs can do, even though they‚Äôre supposed to be designed without having LLMs in mind. A benchmark that tests a faculty of Human Intelligence like ‚Äúreasoning‚Äù should not only explore define reasoning as . This is in contrast to designing theory-laden benchmarks. No one knows the exact definition of Human capacities like ‚Äúreasoning‚Äù, so the design of a benchmark must have assumptions on what are the definitions of whatever capacity it is measuring. The key argument of the present article is that such assumptions have been constrained to framing every faculty as the prediction of the next token, where token can be the next word, image or audio signal. I don‚Äôt even know what faculties like ‚Äúmemory‚Äù, ‚Äúreasoning‚Äù, ‚Äúplanning‚Äù are. But I do know as many researchers may conclude after years of work on this, that it is <em>not just contextualized, next-state prediction</em>.</p> <p>Because all benchmarks have been designed based on next-token prediction, it is not surprising that a next-token predictor can perform well. Quiet the opposite, it would be surprising if a next-token predictor can‚Äôt perform well on an auto-regressive task. However, while Human Intelligence most likely consists of next-token prediction, it would be misleading to suggest it <em>only</em> consists of this process. By that line of thought, LLMs haven‚Äôt even passed the Turing Test, at least by its <a href="https://en.wikipedia.org/wiki/Computing_Machinery_and_Intelligence">original formulation</a>. This is because while it is true that the original objective was for a machine to imitate a human and fool an interrogator, a feat that LLMs can already achieve by producing text that is indistinguishable from Human-produced text, it is often ignored that the Turing Test is executed via a <em>physical</em> exchange of written letters. I don‚Äôt think this is a trivial matter that can be glanced over, as it is very important to note that LLMs can not write, since they are not instantiated in spacetime, nor have a body with which they have to face the challenge of sensorimotor control in a continuous feedback loop.</p> <p>A benchmark of a faculty of Intelligence shouldn‚Äôt be designed with only one theory of what Intelligence is, i.e., prediction of next-token. This kind of practice is akin to framing questions based on the answer one expects, instead of asking open-ended questions for the sake of curiosity. As such, if I may borrow the sensationalist attitudes of some media personalities, I just want to say ‚Äúall these benchmarks are wrong, and none of them are useful<sup id="fnref:1"><a href="#fn:1" class="footnote" rel="footnote" role="doc-noteref">1</a></sup> to understand Intelligence‚Äù.</p> <h2 id="prediction-error-minimization-is-a-strong-hypothesis-not-overarching">Prediction Error Minimization is a strong hypothesis, not overarching</h2> <p>I do want to clarify: I think <a href="https://www.fil.ion.ucl.ac.uk/~karl/Whatever%20next.pdf">prediction error minimization (PEM)</a> as an integral part of Human intelligence is a resilient hypothesis. Active inference, for instance, states that our brains are constantly predicting the source of the signals we perceive, and consciousness is the result when we infer that the cause of some signals in the environment is caused by ourselves. PEM also tries to explain other phenomena like dreaming, arguing that it is a form of ‚Äúreverse-learning‚Äù that consists of a process of flushing irrelevant memories to while strengthening important synaptic connections, altogether allocate mental resources to make better predictions afterwards. Another important strength of the PEM hypothesis is that the abstract process of ‚Äúlearning‚Äù is grounded to physical mechanisms like chemico-modulated, neuronal activations. I believe these are very strong hypothesis that can withstand harsh criticism. I simply think PEM is not enough to explain the entirety of the Human condition.</p> <figure> <img src="/assets/img/llm_shouting.jpg" alt="Sorry, an unanticipated error occured and the image can't load." width="100%" height="auto"/> <figcaption id="llm"> Image generated by Dall-E powered MS Bing Image Creator given the prompt "a large language model shouting" </figcaption> </figure> <p>My main criticism of PEM is that while it is designed to explain Human intelligence, it seems that it makes no distinction between non-Human animal intelligence and Human intelligence. The non-Human animal brain also has neurons firing, and the PEM may well apply to non-Human animals and Humans alike. However, is that enough? Are we Humans really just a slightly more intelligent animal. I argue it is absolutely not. Non-human animals can‚Äôt reflect on the mysteries of the mechanisms of the universe, perform scientific experiments, do creative thinking, believe in currency exchange and laundering, or any activity beyond the shackles of genetic predisposition, among others. And furthermore, I don‚Äôt think PEM explains neither of the aforementioned capacities.</p> <p>I just hope sensationalist claims in media stay as they are: ‚Äúsensationalist‚Äù. They‚Äôre only meant to spark sensation, not actually to determine the course of public-policy making (at least not now), instilling fear of Humanity‚Äôs imminent destruction or even <a href="https://www.youtube.com/watch?v=lfXxzAVtdpU">existential crisis</a> on what humanity is. What I‚Äôm most worried about is that these sensationalist claims limit our own perspective on how amazing Human intelligence is, and that it is beyond PEM.</p> <p>As previously said, I don‚Äôt know what Human intelligence is in its entirety, but I‚Äôm confident it at least includes in addition to learning: reasoning, sensorimotor control, creativity/imagination, curiosity, consciousness, intrapersonal understanding, interpersonal understanding, among others.</p> <h1 id="proposing-an-extended-turing-test">Proposing an Extended Turing Test</h1> <p>To share some thoughts on a more comprehensive Turing Test, I do want to clarify that it is designed to measure Intelligence, not accuracy of next-predicted tokens. As such, a preliminary concept to convey concerns <a href="https://hrstraub.ch/en/the-theory-of-the-three-worlds-penrose/">Roger Penrose‚Äôs 3 worlds</a>: 1) Platonic, 2) Physical and 3) Subjective. Almost all existing benchmarks measuring any faculty of Human Intelligence, such as to produce language, focus on evaluating in the Platonic space, the space of abstract ideas. There do exist benchmarks measuring faculties in the physical space, such as in robotics, with examples including (cute) <a href="https://www.youtube.com/watch?v=RbyQcCT6890">robots playing football</a> against one another <sup id="fnref:2"><a href="#fn:2" class="footnote" rel="footnote" role="doc-noteref">2</a></sup>, however, these benchmarks then don‚Äôt measure faculties in Platonic space.</p> <p>I will also focus on the breadth of tasks, instead of the depth. This means the Extended Turing Test (better named Extended Turing Benchmark) has as many diverse tasks as possible, instead of having a single task modality, such as predicting the next text-token, but it is semantically diverse within this domain (predict the next token in English, in Spanish, in Chinese, among others). Following the main idea of this article, I won‚Äôt be focusing on next-token prediction either, though it is an integral part of it. I also note this is not meant to be the final Extended Turing Benchmark, and feedback is most welcomed.</p> <table> <thead> <tr> <th>Task</th> <th>Challenging aspects</th> </tr> </thead> <tbody> <tr> <td>Solve a mathematical conjecture, like Goldbach‚Äôs Conjecture</td> <td>The answer is not given in the training set</td> </tr> <tr> <td>Achieve a United Nation‚Äôs Sustainable Development Goal</td> <td>Requires interplay of Platonic and Physical space</td> </tr> <tr> <td>Find a cure for a disease of global concern</td> <td>Requires physical experimentation and searching over hypothesis space</td> </tr> <tr> <td>Propose a plan for a successful start-up</td> <td>Same as above</td> </tr> <tr> <td>Break a world record</td> <td>Same as above</td> </tr> <tr> <td>Ask questions</td> <td>Same as above</td> </tr> <tr> <td>Solve a conflict of global concern</td> <td>Requires interplay of Platonic, Physical and Subjective spaces</td> </tr> <tr> <td>Open-ended debate on moral dilemmas, such as the Trolley Problem</td> <td>No correct answer, requires proficiency in Subjective space</td> </tr> </tbody> </table> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:1"> <p>I don‚Äôt actually mean all benchmarks are wrong. Some benchmarks have indeed yielded insight into what constitutes Human intelligence, and they are good attempts at quantifying faculties of intelligence like visual reasoning, and analogy-making.¬†<a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:2"> <p>The match caused some sensation despite it is not played against humans, further exacerbating a point made earlier that sensorimotor control, in addition to PEM, is an integral part of Intelligence. As such, I can‚Äôt understand how and why autoregressive models are advertised as the key to Artificial General Intelligence.¬†<a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> </ol> </div>]]></content><author><name></name></author><category term="blog-post"/><category term="food-for-thought"/><category term="creative-work"/><summary type="html"><![CDATA[I argue we Humans are more than next-state prediction machines.]]></summary></entry><entry><title type="html">Concept-Bottleneck Modelling for Interpretable Melanoma Classification</title><link href="https://awxlong.github.io/blog/2023/concept-melanoma/" rel="alternate" type="text/html" title="Concept-Bottleneck Modelling for Interpretable Melanoma Classification"/><published>2023-12-04T16:42:00+00:00</published><updated>2023-12-04T16:42:00+00:00</updated><id>https://awxlong.github.io/blog/2023/concept-melanoma</id><content type="html" xml:base="https://awxlong.github.io/blog/2023/concept-melanoma/"><![CDATA[<p>Redirecting to another page.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[A research project adopting the concept-bottleneck modelling technique for interpretable melanoma classification.]]></summary></entry><entry><title type="html">Review of the paper Learning biophysical determinants of cell fate with deep neural networks</title><link href="https://awxlong.github.io/blog/2023/biophysical/" rel="alternate" type="text/html" title="Review of the paper Learning biophysical determinants of cell fate with deep neural networks"/><published>2023-11-02T19:42:00+00:00</published><updated>2023-11-02T19:42:00+00:00</updated><id>https://awxlong.github.io/blog/2023/biophysical</id><content type="html" xml:base="https://awxlong.github.io/blog/2023/biophysical/"><![CDATA[<h1 id="brief-summary">Brief summary</h1> <p>The paper by <d-cite key="dsa_2023_prediction"></d-cite> leverages deep learning architectures to solve a pentanary classification task given either a cell‚Äôs tabular features or images. The five independent classes are one healthy control and four subtypes of Parkinson‚Äôs Disease: familial proteinopathy (SNCA), environmental proteinopathy (\(\alpha\)-Syn oligomer), and two subtypes characterized by different mitochondria dysfunction pathways. These pathologies were chemically induced on stem cells. Fifty-six phenotypical features of them were extracted automatically and recorded as tabular data, along with images of the cells extracted via microscopy. Both data modalities were labeled with one of the five classes.</p> <p>The research team trained separately a dense feedforward neural network (DNN) to classify on the tabular data, as well as a convolutional neural network (CNN) to classify on image data. The test classification accuracy achieved by the DNN reached around 83%, while the CNN 95%.</p> <figure> <img src="/assets/img/parkinson.png" alt="Sorry. Image couldn't load." width="100%" height="auto"/> <figcaption id="bottleneck">Two separate models are trained on different datasets on the same task of Parkinson subtype classification. Figure extracted from the original research article at https://www.nature.com/articles/s42256-023-00702-9</figcaption> </figure> <h1 id="my-comments-and-future-research-directions">My comments and future research directions</h1> <p>Generally, in the deep learning literature, it is acknowledged that the usage of DNNs comes at the expense of poor explainability. Despite achieving high classification accuracy, these models are black-boxes. Nonetheless, there are ways to identify what are the features that the neural networks pay the most attention when deciding on a classification label, mainly by looking at its last layer‚Äôs activation and tracing back to the input space which input feature is associated to it. In CNNs, the technique employed by the research team is called the ShAP (SHapley Additive exPlanations) method.</p> <p>The authors managed to identify in both the DNN and CNN that the mitochondria, lysosome and the interaction of both features mainly contributed to the classification decisions of both models.</p> <p>One future research direction concerns whether integrating both data sources can improve performance and yield explainability, because the original work trains separate models, trained on different datasets.</p> <p>One source of inspiration is from <d-cite key="li_2023_v1t"></d-cite>, where they integrate image data along with a mouse‚Äôs behavioral features to predict its neural responses collected from neural recordings. Another source of inspiration is drawn from concept-bottleneck models <d-cite key="koh_2020_concept"></d-cite>. There, a CNN in charge of processing images doesn‚Äôt learn to output a classification label, but instead to output features that are relevant to the image. These features, in turn, are annotations of the image stored in tabular:</p> <figure> <img src="/assets/img/bottleneck.png" alt="Sorry. Image couldn't load." width="100%" height="auto"/> <figcaption id="bottleneck">A depiction of the pipeline of a concept-bottleneck model. The first half outputs a set of concepts given an image, which can be learnt from intricate annotations, or metadata, of the image. The second half outputs a classification label. Figure extracted from the original paper </figcaption> </figure> <p>Altogether, with regards to the work by <d-cite key="dsa_2023_prediction"></d-cite>, one interesting extension to their CNN is to have it not predict a Parkinson subtype, but rather learn to predict the cell‚Äôs physiological features stored as tabular data given image input. Subsequently, use the features to train a multi-class regressor using standard softmax to output a classification label. The prospect is that this hybrid model can leverage the high accuracy prediction of the CNN, whilst being explainable thanks to the logistic regressor.</p> <p>As a further improvement, we can use a <a href="https://arxiv.org/abs/2210.11394">Slot Transformer</a> instead of the CNN with the hope of learning a disentangled representation given the image with its annotations. However, the architecture will be more computationally expensive. A pretrained Slot Transformer that already learnt to disentangle CLEVR-Scenes may be more powerful than training it from scratch.</p>]]></content><author><name>Xuelong An</name></author><category term="blog-post"/><category term="research"/><summary type="html"><![CDATA[comments on a paper that leverages deep learning to classify epithelium cell fate by observing its live image trajectory.]]></summary></entry><entry><title type="html">Review of the paper A Deep Learning Approach to Antibiotic Discovery</title><link href="https://awxlong.github.io/blog/2023/halicin/" rel="alternate" type="text/html" title="Review of the paper A Deep Learning Approach to Antibiotic Discovery"/><published>2023-11-02T19:42:00+00:00</published><updated>2023-11-02T19:42:00+00:00</updated><id>https://awxlong.github.io/blog/2023/halicin</id><content type="html" xml:base="https://awxlong.github.io/blog/2023/halicin/"><![CDATA[<style>.pdf-embed-wrap-e8083fa8-573f-4b0f-80b2-8993b6ba8552{display:flex;flex-direction:column;width:100%;height:650px}.pdf-embed-container-e8083fa8-573f-4b0f-80b2-8993b6ba8552{height:100%}.pdf-link-e8083fa8-573f-4b0f-80b2-8993b6ba8552{background-color:white;text-align:center;border-style:solid}.pdf-embed-container-e8083fa8-573f-4b0f-80b2-8993b6ba8552 iframe{width:100%;height:100%}</style> <div class="pdf-embed-wrap-e8083fa8-573f-4b0f-80b2-8993b6ba8552"> <div class="pdf-link-e8083fa8-573f-4b0f-80b2-8993b6ba8552"> <a href="/assets/pdf/review_antibiotic.pdf" target="_blank">View PDF</a> </div> <div class="pdf-embed-container-e8083fa8-573f-4b0f-80b2-8993b6ba8552"> <iframe src="/assets/pdf/review_antibiotic.pdf" frameborder="0" allowfullscreen=""></iframe> </div> </div>]]></content><author><name>Xuelong An</name></author><category term="blog-post"/><category term="research"/><summary type="html"><![CDATA[comments on the paper "A Deep Learning Approach to Antibiotic Discovery", with a brief step-by-step algorithm how message passsing works in a graph neural network]]></summary></entry><entry><title type="html">Review of the paper Prediction of mechanistic subtypes of Parkinson‚Äôs using patient derived stem cell models</title><link href="https://awxlong.github.io/blog/2023/mechanistic-subtypes-parkinson-copy-copy/" rel="alternate" type="text/html" title="Review of the paper Prediction of mechanistic subtypes of Parkinson‚Äôs using patient derived stem cell models"/><published>2023-11-02T19:42:00+00:00</published><updated>2023-11-02T19:42:00+00:00</updated><id>https://awxlong.github.io/blog/2023/mechanistic-subtypes-parkinson-copy%20copy</id><content type="html" xml:base="https://awxlong.github.io/blog/2023/mechanistic-subtypes-parkinson-copy-copy/"><![CDATA[<h1 id="brief-summary">Brief summary</h1> <p>The paper by <d-cite key="dsa_2023_prediction"></d-cite> leverages deep learning architectures to solve a pentanary classification task given either a cell‚Äôs tabular features or images. The five independent classes are one healthy control and four subtypes of Parkinson‚Äôs Disease: familial proteinopathy (SNCA), environmental proteinopathy (\(\alpha\)-Syn oligomer), and two subtypes characterized by different mitochondria dysfunction pathways. These pathologies were chemically induced on stem cells. Fifty-six phenotypical features of them were extracted automatically and recorded as tabular data, along with images of the cells extracted via microscopy. Both data modalities were labeled with one of the five classes.</p> <p>The research team trained separately a dense feedforward neural network (DNN) to classify on the tabular data, as well as a convolutional neural network (CNN) to classify on image data. The test classification accuracy achieved by the DNN reached around 83%, while the CNN 95%.</p> <figure> <img src="/assets/img/parkinson.png" alt="Sorry. Image couldn't load." width="100%" height="auto"/> <figcaption id="bottleneck">Two separate models are trained on different datasets on the same task of Parkinson subtype classification. Figure extracted from the original research article at https://www.nature.com/articles/s42256-023-00702-9</figcaption> </figure> <h1 id="my-comments-and-future-research-directions">My comments and future research directions</h1> <p>Generally, in the deep learning literature, it is acknowledged that the usage of DNNs comes at the expense of poor explainability. Despite achieving high classification accuracy, these models are black-boxes. Nonetheless, there are ways to identify what are the features that the neural networks pay the most attention when deciding on a classification label, mainly by looking at its last layer‚Äôs activation and tracing back to the input space which input feature is associated to it. In CNNs, the technique employed by the research team is called the ShAP (SHapley Additive exPlanations) method.</p> <p>The authors managed to identify in both the DNN and CNN that the mitochondria, lysosome and the interaction of both features mainly contributed to the classification decisions of both models.</p> <p>One future research direction I am interested is exploring whether by integrating both data sources can improve performance and yield explainability, because the original work trains separate models, trained on different datasets.</p> <p>One source of inspiration is from <d-cite key="li_2023_v1t"></d-cite>, where they integrate image data along with a mouse‚Äôs behavioral features to predict its neural responses collected from neural recordings. Another source of inspiration is drawn from concept-bottleneck models <d-cite key="koh_2020_concept"></d-cite>. There, a CNN in charge of processing images doesn‚Äôt learn to output a classification label, but instead to output features that are relevant to the image. These features, in turn, are annotations of the image stored in tabular:</p> <figure> <img src="/assets/img/bottleneck.png" alt="Sorry. Image couldn't load." width="100%" height="auto"/> <figcaption id="bottleneck">A depiction of the pipeline of a concept-bottleneck model. The first half outputs a set of concepts given an image, which can be learnt from intricate annotations, or metadata, of the image. The second half outputs a classification label. Figure extracted from the original paper </figcaption> </figure> <p>Altogether, with regards to the work by <d-cite key="dsa_2023_prediction"></d-cite>, one interesting extension to their CNN is to have it not predict a Parkinson subtype, but rather learn to predict the cell‚Äôs physiological features stored as tabular data given image input. Subsequently, use the features to train a multi-class regressor using standard softmax to output a classification label. The prospect is that this hybrid model can leverage the high accuracy prediction of the CNN, whilst being explainable thanks to the logistic regressor.</p> <p>As a further improvement, we can use a <a href="https://arxiv.org/abs/2210.11394">Slot Transformer</a> instead of the CNN with the hope of learning a disentangled representation given the image with its annotations. However, the architecture will be more computationally expensive. A pretrained Slot Transformer that already learnt to disentangle CLEVR-Scenes may be more powerful than training it from scratch.</p>]]></content><author><name>Xuelong An</name></author><category term="blog-post"/><category term="research"/><summary type="html"><![CDATA[comments on a paper that leverages deep learning to classify cells into Parkinson's subtypes]]></summary></entry></feed>