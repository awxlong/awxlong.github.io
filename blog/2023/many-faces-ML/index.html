<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>The many interpretations of terms in artificial intelligence | Xuelong An Wang</title> <meta name="author" content="Xuelong An Wang"> <meta name="description" content="Some thoughts concerning how to interpret quotidian words appearing in AI research: knowledge, explanation, etc."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link href="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.css" rel="stylesheet"> <link rel="shortcut icon" href="/assets/img/brain-fractal-3.jpg"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://awxlong.github.io/blog/2023/many-faces-ML/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Xuelong </span>An Wang</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">research</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">The many interpretations of terms in artificial intelligence</h1> <p class="post-meta">November 1, 2023</p> <p class="post-tags"> <a href="/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a>   ·   <a href="/blog/tag/food-for-thought"> <i class="fas fa-hashtag fa-sm"></i> food-for-thought</a>     ·   <a href="/blog/category/blog-post"> <i class="fas fa-tag fa-sm"></i> blog-post</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <p>I bumped into this paper on <a href="https://twitter.com/ChristophMolnar" rel="external nofollow noopener" target="_blank">X (formerly Twitter)</a></p> <div class="jekyll-twitter-plugin"> <blockquote class="twitter-tweet"> <p lang="en" dir="ltr">How do researchers define interpretability and explainability?<br><br>An overview:<a href="https://t.co/bNjKv8F44g" rel="external nofollow noopener" target="_blank">https://t.co/bNjKv8F44g</a> <br><br>Summary: No consensus<br><br>My opinion: It's already the Wild West, no one will stick to any definition. Most pragmatic is to treat them interchangeably. <a href="https://t.co/mEh6mUuk4C" rel="external nofollow noopener" target="_blank">pic.twitter.com/mEh6mUuk4C</a></p>— Christoph Molnar 🦋 christophmolnar.bsky.social (@ChristophMolnar) <a href="https://twitter.com/ChristophMolnar/status/1718921189333045752?ref_src=twsrc%5Etfw" rel="external nofollow noopener" target="_blank">October 30, 2023</a> </blockquote> <script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> </div> <p>In today’s post, I don’t want to discuss interpretability or explainability, but rather elaborate on the above idea that in the AI literature, different authors express completely different ideas despite using the same words, often words that appear in our daily parlance, yet acquire uncommon interpretations.</p> <p>If you have just set foot into the world of artificial intelligence, here are my thoughts and advices on navigating this exciting, but often messy landscape.</p> <h1 id="terms">Terms</h1> <h4 id="explanation-hypothesis-model"><strong>Explanation, hypothesis, model</strong></h4> <p>When I began studying AI, the word “model” elicited the mental imagery of a 3D scale model of something. If I wanted a “model” of an atom, I could pick some recycled styrofoam balls, stick them together and, bam (pun intended), an atom is synthesized.</p> <p>Nowadays it mainly refers to a equation or function with some parameters $\theta$, where a ‘good’ model is defined as having optimal parameters $\theta$ that can make predictions with low error on the training and (hopefully) unseen, test data, compared to a ‘bad’ model.</p> <p>In rare cases, such as in <a href="https://www.youtube.com/watch?v=NsID1iM8gRw" rel="external nofollow noopener" target="_blank">Prof. Joshua Tenembaum’s talk on Cognition</a>, a (physics-) model can refer a simulator implemented in Unity.</p> <h4 id="knowledge"><strong>Knowledge</strong></h4> <p>This word may cause some confusion to peers with a philosophy or psychology background. At least to me, prior to studying AI, ‘knowledge’ meant pieces of information encoded in natural language, e.g. “Mount Chimborazo is actually higher than Mount Everest” somewhere in the brain. I don’t know how, nor where, nor whether it is encoded in natural language.</p> <p>At least in the early days of AI, first order logic constraints such as <code class="language-plaintext highlighter-rouge">smoker(X) :- edema(X)</code>, read as “it is true that if X is a smoker, then X has edema”, does resemble ‘knowledge’ encoded in a way that seems familiar to us.</p> <p>However, this is not always the case. The word ‘knowledge’, such as in ‘prior knowledge’, mainly used in Bayesian modelling, has not much to do with logic predicates or natural language. It mainly refers to what you believe on the distribution of the parameters of your model come from before your model is trained on any data. If you think your model must be parametrized by weights that more often take extreme values, you can set a prior belief with distributions with heavier tails. Guidance on what prior distributions can be used to describe your parameters can be checked in this <a href="https://twitter.com/bindureddy/status/1708664380987220427" rel="external nofollow noopener" target="_blank">tweext</a></p> <p>Lastly, sometimes researchers may even say that ‘knowledge’ of the data is encoded in the parameters of the model, which leads us to the next section:</p> <h4 id="explainability-and-interpretability"><strong>Explainability and interpretability</strong></h4> <p>Explainability and interpretability are terms that can be used interchangeably, as shown in the above paper. I avoid making a distinction in this post, and just focus on sharing what is usually meant by either term.</p> <p>The simplest manifestation of explainability can be observed with simple linear models like linear or logistic regression. Here explainability simply refers to the presence of coefficients estimated per each input variable of the model. These coefficients’ magnitudes often denote the contribution of the variable to the overall prediction of the model. Other non-linear, machine learning models such as decision trees are by design explainable, and such quality mainly refers to the thresholds appearing at each junction in the decision trees.</p> <p>Concerning deep learning, particularly convolutional neural networks (CNN), explainability can refer to the computation of feature maps on the input space to see on average, what are the filters of the CNN observing when solving a task like classification given an image. Deep generative models (DGM) that leverage neural networks and learn latent representations of the data can also become ‘explainable’ if there is some post-hoc (i.e. after training) processing of embeddings, such as dimensionality reduction through principal component analysis, that can map the embeddings on 2D space. In such space, it is hoped that the DGM learns disentangled features, albeit how are they interpreted is mainly up to the researchers, not by some objective reason.</p> <p>Explainability in the eyes of some authors may also refer to the capability of the researcher to compute a numerical value of the likelihood of the parameters of the data, or at least an approximation of it, such as the evidence lower bound. This scalar value can be used to compare the performance of different models, and these models can thus be referred to as “provable”.</p> <p>Other authors may also define explainability when deep neural networks, despite being black boxes, can accept inputs or display its predictions through a user-friendly interface that allows them to interact with the model.</p> <h1 id="bottom-line">Bottom line</h1> <p>My key advice in this brief article is to convince you not to trust the “intuitive” interpretation of a word, especially if it is used on a quotidian basis. For example, in my personal view, to be “explainable” means to be able to justify its own answer. Just like a friend to whom I ask why didn’t they go to a concert by singer Aimer, to be “explainable” (at least when referring to the common meaning of this word in daily life) means that they can give a justification as to why didn’t they go (maybe they became sick, or admit they have poor taste in music). ‘Explainable’ in the machine learning literature has not much to do with this daily life interpretation.</p> <p>Finally, the above terms are simply the tip of the iceberg. In the wider research literature, authors can diverge in what they mean by on many terms such as “language”, the word “intelligence” itself, and more controversial terms like “artificial general intelligence”. Because I don’t know the precise meaning of them myself, I refrain from commenting furthermore.</p> <p>Happy learning!</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/master-algorithm/">On thoughts about the Master Algorithm</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/luis-UG/">Gramática universal y una gallina</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/benchmarks/">Goedel Benchmarks: self-improving benchmarks</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/arc/">A brief take on benchmarks</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/tertulia-kennedy/">Conversatoria sobre la inteligencia artificial en la medicina</a> </li> <div id="disqus_thread" style="max-width: 800px; margin: 0 auto;"> <script type="text/javascript">var disqus_shortname="al-folio",disqus_identifier="/blog/2023/many-faces-ML",disqus_title="The many interpretations of terms in artificial intelligence";!function(){var e=document.createElement("script");e.type="text/javascript",e.async=!0,e.src="//"+disqus_shortname+".disqus.com/embed.js",(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(e)}();</script> <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by Disqus.</a> </noscript> </div> </div> </div> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Xuelong An Wang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.js"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?07eaa7cf937a07ef341b1faf1776b8cf"></script> <script defer src="/assets/js/common.js?85108440d5ed580d281b2dcc25e2b2d9"></script> <script defer src="/assets/js/copy_code.js?bd78cf329e9ccb6ed226722e0a87ad8e" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>