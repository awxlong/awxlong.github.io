<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>On the Turing Test and Large Language Models | Xuelong An Wang</title> <meta name="author" content="Xuelong An Wang"> <meta name="description" content="I argue we Humans are more than next-state prediction machines."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link href="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.css" rel="stylesheet"> <link rel="shortcut icon" href="/assets/img/brain-fractal-3.jpg"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://awxlong.github.io/blog/2023/turing-test/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Xuelong </span>An Wang</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">research</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">On the Turing Test and Large Language Models</h1> <p class="post-meta">December 9, 2023</p> <p class="post-tags"> <a href="/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a>   ·   <a href="/blog/tag/food-for-thought"> <i class="fas fa-hashtag fa-sm"></i> food-for-thought</a>   <a href="/blog/tag/creative-work"> <i class="fas fa-hashtag fa-sm"></i> creative-work</a>     ·   <a href="/blog/category/blog-post"> <i class="fas fa-tag fa-sm"></i> blog-post</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <h1 id="on-benchmarks-of-human-intelligence">On benchmarks of Human intelligence</h1> <p>There is a plethora of claims surrounding the emergence of actual or surpasssing Human intelligence by Large Language Models. One, by one, these contextualized autocomplete models are given the labels of having <a href="https://arxiv.org/abs/2305.03731v2" rel="external nofollow noopener" target="_blank">working memory</a>, <a href="https://analyticsindiamag.com/text-is-a-projection-of-the-world-says-openais-sutskever/" rel="external nofollow noopener" target="_blank">compresses</a> a <a href="https://www.linkedin.com/posts/armand-ruiz_llms-do-more-than-predict-the-next-word-activity-7134512576318623744-7BlG?utm_source=share&amp;utm_medium=member_desktop" rel="external nofollow noopener" target="_blank">“world model”</a>, or it signals <a href="https://arxiv.org/abs/2303.12712" rel="external nofollow noopener" target="_blank">sparks of Artificial General Intelligence</a>.</p> <p>There are a list of benchmarks backing up their claims. These benchmarks come with questions-answers pairs, where high performance signifies that a model is able to simulate a faculty of Human intelligence like language.</p> <p>However, most if not all benchmarks are tailored for what LLMs can do, even though they’re supposed to be designed without having LLMs in mind. A benchmark that tests a faculty of Human Intelligence like “reasoning” should not only explore define reasoning as . This is in contrast to designing theory-laden benchmarks. No one knows the exact definition of Human capacities like “reasoning”, so the design of a benchmark must have assumptions on what are the definitions of whatever capacity it is measuring. The key argument of the present article is that such assumptions have been constrained to framing every faculty as the prediction of the next token, where token can be the next word, image or audio signal. I don’t even know what faculties like “memory”, “reasoning”, “planning” are. But I do know as many researchers may conclude after years of work on this, that it is <em>not just contextualized, next-state prediction</em>.</p> <p>Because all benchmarks have been designed based on next-token prediction, it is not surprising that a next-token predictor can perform well. Quiet the opposite, it would be surprising if a next-token predictor can’t perform well on an auto-regressive task. However, while Human Intelligence most likely consists of next-token prediction, it would be misleading to suggest it <em>only</em> consists of this process. By that line of thought, LLMs haven’t even passed the Turing Test, at least by its <a href="https://en.wikipedia.org/wiki/Computing_Machinery_and_Intelligence" rel="external nofollow noopener" target="_blank">original formulation</a>. This is because while it is true that the original objective was for a machine to imitate a human and fool an interrogator, a feat that LLMs can already achieve by producing text that is indistinguishable from Human-produced text, it is often ignored that the Turing Test is executed via a <em>physical</em> exchange of written letters. I don’t think this is a trivial matter that can be glanced over, as it is very important to note that LLMs can not write, since they are not instantiated in spacetime, nor have a body with which they have to face the challenge of sensorimotor control in a continuous feedback loop.</p> <p>A benchmark of a faculty of Intelligence shouldn’t be designed with only one theory of what Intelligence is, i.e., prediction of next-token. This kind of practice is akin to framing questions based on the answer one expects, instead of asking open-ended questions for the sake of curiosity. As such, if I may borrow the sensationalist attitudes of some media personalities, I just want to say “all these benchmarks are wrong, and none of them are useful<sup id="fnref:1"><a href="#fn:1" class="footnote" rel="footnote" role="doc-noteref">1</a></sup> to understand Intelligence”.</p> <h2 id="prediction-error-minimization-is-a-strong-hypothesis-not-overarching">Prediction Error Minimization is a strong hypothesis, not overarching</h2> <p>I do want to clarify: I think <a href="https://www.fil.ion.ucl.ac.uk/~karl/Whatever%20next.pdf" rel="external nofollow noopener" target="_blank">prediction error minimization (PEM)</a> as an integral part of Human intelligence is a resilient hypothesis. Active inference, for instance, states that our brains are constantly predicting the source of the signals we perceive, and consciousness is the result when we infer that the cause of some signals in the environment is caused by ourselves. PEM also tries to explain other phenomena like dreaming, arguing that it is a form of “reverse-learning” that consists of a process of flushing irrelevant memories to while strengthening important synaptic connections, altogether allocate mental resources to make better predictions afterwards. Another important strength of the PEM hypothesis is that the abstract process of “learning” is grounded to physical mechanisms like chemico-modulated, neuronal activations. I believe these are very strong hypothesis that can withstand harsh criticism. I simply think PEM is not enough to explain the entirety of the Human condition.</p> <figure> <img src="/assets/img/llm_shouting.jpg" alt="Sorry, an unanticipated error occured and the image can't load." width="100%" height="auto"> <figcaption id="llm"> Image generated by Dall-E powered MS Bing Image Creator given the prompt "a large language model shouting" </figcaption> </figure> <p>My main criticism of PEM is that while it is designed to explain Human intelligence, it seems that it makes no distinction between non-Human animal intelligence and Human intelligence. The non-Human animal brain also has neurons firing, and the PEM may well apply to non-Human animals and Humans alike. However, is that enough? Are we Humans really just a slightly more intelligent animal. I argue it is absolutely not. Non-human animals can’t reflect on the mysteries of the mechanisms of the universe, perform scientific experiments, do creative thinking, believe in currency exchange and laundering, or any activity beyond the shackles of genetic predisposition, among others. And furthermore, I don’t think PEM explains neither of the aforementioned capacities.</p> <p>I just hope sensationalist claims in media stay as they are: “sensationalist”. They’re only meant to spark sensation, not actually to determine the course of public-policy making (at least not now), instilling fear of Humanity’s imminent destruction or even <a href="https://www.youtube.com/watch?v=lfXxzAVtdpU" rel="external nofollow noopener" target="_blank">existential crisis</a> on what humanity is. What I’m most worried about is that these sensationalist claims limit our own perspective on how amazing Human intelligence is, and that it is beyond PEM.</p> <p>As previously said, I don’t know what Human intelligence is in its entirety, but I’m confident it at least includes in addition to learning: reasoning, sensorimotor control, creativity/imagination, curiosity, consciousness, intrapersonal understanding, interpersonal understanding, among others.</p> <h1 id="proposing-an-extended-turing-test">Proposing an Extended Turing Test</h1> <p>To share some thoughts on a more comprehensive Turing Test, I do want to clarify that it is designed to measure Intelligence, not accuracy of next-predicted tokens. As such, a preliminary concept to convey concerns <a href="https://hrstraub.ch/en/the-theory-of-the-three-worlds-penrose/" rel="external nofollow noopener" target="_blank">Roger Penrose’s 3 worlds</a>: 1) Platonic, 2) Physical and 3) Subjective. Almost all existing benchmarks measuring any faculty of Human Intelligence, such as to produce language, focus on evaluating in the Platonic space, the space of abstract ideas. There do exist benchmarks measuring faculties in the physical space, such as in robotics, with examples including (cute) <a href="https://www.youtube.com/watch?v=RbyQcCT6890" rel="external nofollow noopener" target="_blank">robots playing football</a> against one another <sup id="fnref:2"><a href="#fn:2" class="footnote" rel="footnote" role="doc-noteref">2</a></sup>, however, these benchmarks then don’t measure faculties in Platonic space.</p> <p>I will also focus on the breadth of tasks, instead of the depth. This means the Extended Turing Test (better named Extended Turing Benchmark) has as many diverse tasks as possible, instead of having a single task modality, such as predicting the next text-token, but it is semantically diverse within this domain (predict the next token in English, in Spanish, in Chinese, among others). Following the main idea of this article, I won’t be focusing on next-token prediction either, though it is an integral part of it. I also note this is not meant to be the final Extended Turing Benchmark, and feedback is most welcomed.</p> <table> <thead> <tr> <th>Task</th> <th>Challenging aspects</th> </tr> </thead> <tbody> <tr> <td>Solve a mathematical conjecture, like Goldbach’s Conjecture</td> <td>The answer is not given in the training set</td> </tr> <tr> <td>Achieve a United Nation’s Sustainable Development Goal</td> <td>Requires interplay of Platonic and Physical space</td> </tr> <tr> <td>Find a cure for a disease of global concern</td> <td>Requires physical experimentation and searching over hypothesis space</td> </tr> <tr> <td>Propose a plan for a successful start-up</td> <td>Same as above</td> </tr> <tr> <td>Break a world record</td> <td>Same as above</td> </tr> <tr> <td>Ask questions</td> <td>Same as above</td> </tr> <tr> <td>Solve a conflict of global concern</td> <td>Requires interplay of Platonic, Physical and Subjective spaces</td> </tr> <tr> <td>Open-ended debate on moral dilemmas, such as the Trolley Problem</td> <td>No correct answer, requires proficiency in Subjective space</td> </tr> </tbody> </table> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:1"> <p>I don’t actually mean all benchmarks are wrong. Some benchmarks have indeed yielded insight into what constitutes Human intelligence, and they are good attempts at quantifying faculties of intelligence like visual reasoning, and analogy-making. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">↩</a></p> </li> <li id="fn:2"> <p>The match caused some sensation despite it is not played against humans, further exacerbating a point made earlier that sensorimotor control, in addition to PEM, is an integral part of Intelligence. As such, I can’t understand how and why autoregressive models are advertised as the key to Artificial General Intelligence. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">↩</a></p> </li> </ol> </div> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/manifold-vqa/">Ideas on transitioning from monolith to manifold of models</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/thoughts-deepmind-cell/">Thoughts on How to Build the Virtual Cell with Artificial Intelligence</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/consilience/">phenotype = (genotype + environment) * consciousness. Reflections on The consilience of knowledge by Edward O. Wilson</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/hack-vasculature/">Reflections on the Hacking the Human Vasculature Kaggle Competition</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/pc-imputation/">A probabilistic circuit for imputing missing tabular data</a> </li> <div id="disqus_thread" style="max-width: 800px; margin: 0 auto;"> <script type="text/javascript">var disqus_shortname="al-folio",disqus_identifier="/blog/2023/turing-test",disqus_title="On the Turing Test and Large Language Models";!function(){var e=document.createElement("script");e.type="text/javascript",e.async=!0,e.src="//"+disqus_shortname+".disqus.com/embed.js",(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(e)}();</script> <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by Disqus.</a> </noscript> </div> </div> </div> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Xuelong An Wang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.js"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?07eaa7cf937a07ef341b1faf1776b8cf"></script> <script defer src="/assets/js/common.js?85108440d5ed580d281b2dcc25e2b2d9"></script> <script defer src="/assets/js/copy_code.js?bd78cf329e9ccb6ed226722e0a87ad8e" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>